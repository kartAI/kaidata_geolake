{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Demo for styringsmøte den 10.03.2025\n",
    "\n",
    "NB! må kjøre konverting av filer seksjonen først"
   ],
   "id": "f306152f19c8dc8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Installere pakker\n",
   "id": "572d26952da3eda5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:00:33.238238Z",
     "start_time": "2025-03-09T13:00:32.598058Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (18.0.0)\r\n",
      "Requirement already satisfied: geopandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.0.1)\r\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.3)\r\n",
      "Requirement already satisfied: shapely in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.0.6)\r\n",
      "Requirement already satisfied: ipython in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (8.20.0)\r\n",
      "Requirement already satisfied: folium in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.19.5)\r\n",
      "Requirement already satisfied: numpy>=1.22 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from geopandas->-r requirements.txt (line 2)) (1.26.3)\r\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from geopandas->-r requirements.txt (line 2)) (0.10.0)\r\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from geopandas->-r requirements.txt (line 2)) (23.2)\r\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from geopandas->-r requirements.txt (line 2)) (3.7.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\r\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.43)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (2.17.2)\r\n",
      "Requirement already satisfied: stack-data in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.3)\r\n",
      "Requirement already satisfied: traitlets>=5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (5.14.1)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython->-r requirements.txt (line 5)) (4.9.0)\r\n",
      "Requirement already satisfied: branca>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from folium->-r requirements.txt (line 6)) (0.8.1)\r\n",
      "Requirement already satisfied: jinja2>=2.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from folium->-r requirements.txt (line 6)) (3.1.2)\r\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from folium->-r requirements.txt (line 6)) (2.32.3)\r\n",
      "Requirement already satisfied: xyzservices in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from folium->-r requirements.txt (line 6)) (2025.1.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=2.9->folium->-r requirements.txt (line 6)) (2.1.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->-r requirements.txt (line 5)) (0.2.13)\r\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas->-r requirements.txt (line 2)) (2023.11.17)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->folium->-r requirements.txt (line 6)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->folium->-r requirements.txt (line 6)) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->folium->-r requirements.txt (line 6)) (2.1.0)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.0.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.1)\r\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/usr/local/bin/python3.12 -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": "pip install -r requirements.txt",
   "id": "f69b2802439dfce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Importering av pakker"
   ],
   "id": "581ad91ceb0f2708"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:00:10.988415Z",
     "start_time": "2025-03-09T13:00:10.854707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import time as time_module\n",
    "from shapely.geometry import box\n",
    "from IPython.display import display\n",
    "import folium"
   ],
   "id": "8643f97bb8fba72",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Konstante variabler",
   "id": "f6278f3749eaa16a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T12:19:24.249028Z",
     "start_time": "2025-03-07T12:19:24.243354Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 13,
   "source": [
    "ROTMAPPE = \"Data\"\n",
    "PARTISJON_MAPPE_HOUR = f\"{ROTMAPPE}/partitioned_hour\"\n",
    "PARTISJON_MAPPE_MIN = f\"{ROTMAPPE}/partitioned_minutes\""
   ],
   "id": "147bd22c040c302d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Konverting av filer",
   "id": "c0a5c521a45c637f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Opprett mappestruktur",
   "id": "f2bab76ed72d6fc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T12:13:30.066707Z",
     "start_time": "2025-03-07T12:13:30.059836Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "def opprett_mappestruktur(rotmappe):\n",
    "    \"\"\"Oppretter den anbefalte mappestrukturen\"\"\"\n",
    "    mapper = [\n",
    "        os.path.join(rotmappe, 'raw'),\n",
    "        os.path.join(rotmappe, 'processed'),\n",
    "        os.path.join(rotmappe, 'archive')\n",
    "    ]\n",
    "\n",
    "    for mappe in mapper:\n",
    "        os.makedirs(mappe, exist_ok=True)\n",
    "\n",
    "    return {\n",
    "        'raw': mapper[0],\n",
    "        'processed': mapper[1],\n",
    "        'archive': mapper[2]\n",
    "    }"
   ],
   "id": "8a47ebbb3af5e15f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Sjekk innhold i fil",
   "id": "b562ce51d31a9f0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sjekk_metadata_inneholder_geo(schema):\n",
    "    \"\"\"Sjekker om parquet-skjemaet inneholder geo-metadata i noen kolonner\"\"\"\n",
    "    for navn in schema.names:\n",
    "        felt = schema.field(navn)\n",
    "        if felt.metadata and ('geo' in felt.metadata or b'geo' in felt.metadata):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def sjekk_inneholder_geometrikolonne(filsti):\n",
    "    \"\"\"Sjekker om filen inneholder en geometrikolonne ved å lese den med geopandas\"\"\"\n",
    "    gdf = gpd.read_parquet(filsti)\n",
    "    return hasattr(gdf, 'geometry') and gdf.geometry.name in gdf.columns\n",
    "\n",
    "def er_geoparquet(filsti):\n",
    "    \"\"\"Sjekker om en parquet-fil er en GeoParquet-fil ved å undersøke metadata og innhold\"\"\"\n",
    "    # Hvis filen ikke kan leses som parquet, er den ikke en geoparquet\n",
    "    try:\n",
    "        schema = pq.read_schema(filsti)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    # Sjekk metadata\n",
    "    if sjekk_metadata_inneholder_geo(schema):\n",
    "        return True\n",
    "\n",
    "    # Sjekk geometrikolonne i geopandas\n",
    "    try:\n",
    "        return sjekk_inneholder_geometrikolonne(filsti)\n",
    "    except:\n",
    "        return False"
   ],
   "id": "d49103f614cb62e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Konverter fil til geoparquet",
   "id": "193ec508f2a92a7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T12:13:30.008155Z",
     "start_time": "2025-03-07T12:13:29.987631Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "def lag_målfilsti(kildefilsti, målmappesti=None):\n",
    "    \"\"\"Lager målfilsti basert på kildesti og evt. målmappe\"\"\"\n",
    "    base_navn = os.path.basename(kildefilsti)\n",
    "    base_navn_uten_endelse = os.path.splitext(base_navn)[0]\n",
    "\n",
    "    if målmappesti is None:\n",
    "        # Hvis ingen målmappe er angitt, bruk samme mappe med _geo.parquet\n",
    "        dir_navn = os.path.dirname(kildefilsti)\n",
    "        return os.path.join(dir_navn, f\"{base_navn_uten_endelse}_geo.parquet\")\n",
    "    else:\n",
    "        # Hvis målmappe er angitt, plasser filen der\n",
    "        return os.path.join(målmappesti, f\"{base_navn_uten_endelse}.parquet\")\n",
    "\n",
    "def opprett_mappe(filsti):\n",
    "    \"\"\"Sørger for at mappen for filstien eksisterer\"\"\"\n",
    "    os.makedirs(os.path.dirname(filsti), exist_ok=True)\n",
    "\n",
    "def konverter_parquet(filsti):\n",
    "    \"\"\"Konverterer parquet-fil til GeoDataFrame\"\"\"\n",
    "    df = pd.read_parquet(filsti)\n",
    "\n",
    "    # Sjekk etter lat/long kolonner\n",
    "    if 'longitude' in df.columns and 'latitude' in df.columns:\n",
    "        return gpd.GeoDataFrame(\n",
    "            df,\n",
    "            geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "            crs=\"EPSG:4326\"\n",
    "        )\n",
    "\n",
    "    # Sjekk etter potensielle geometrikolonner\n",
    "    geom_kolonner = [col for col in df.columns if 'geom' in col.lower()\n",
    "                   or 'coord' in col.lower()\n",
    "                   or 'point' in col.lower()\n",
    "                   or 'polygon' in col.lower()\n",
    "                   or 'linestring' in col.lower()\n",
    "                   or 'wkt' in col.lower()]\n",
    "\n",
    "    for col in geom_kolonner:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                # Prøv å konvertere fra WKT-format\n",
    "                geom = df[col].apply(wkt.loads)\n",
    "                return gpd.GeoDataFrame(df, geometry=geom, crs=\"EPSG:4326\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return None\n",
    "\n",
    "def konverter_csv(filsti):\n",
    "    \"\"\"Konverterer CSV-fil til GeoDataFrame\"\"\"\n",
    "    df = pd.read_csv(filsti)\n",
    "\n",
    "    # Sjekk for vanlige lat/long kolonnenavn\n",
    "    lat_kolonner = ['latitude', 'lat', 'y', 'breddegrad']\n",
    "    lon_kolonner = ['longitude', 'long', 'lon', 'x', 'lengdegrad']\n",
    "\n",
    "    lat_col = next((col for col in lat_kolonner if col in df.columns), None)\n",
    "    lon_col = next((col for col in lon_kolonner if col in df.columns), None)\n",
    "\n",
    "    if lat_col and lon_col:\n",
    "        return gpd.GeoDataFrame(\n",
    "            df,\n",
    "            geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
    "            crs=\"EPSG:4326\"\n",
    "        )\n",
    "\n",
    "    return None\n",
    "\n",
    "def konverter_fil_basert_på_type(filsti, filendelse):\n",
    "    \"\"\"Konverterer fil til GeoDataFrame basert på filendelse\"\"\"\n",
    "    if filendelse == '.parquet':\n",
    "        return konverter_parquet(filsti)\n",
    "\n",
    "    elif filendelse in ['.geojson', '.json']:\n",
    "        return gpd.read_file(filsti)\n",
    "\n",
    "    elif filendelse == '.shp':\n",
    "        return gpd.read_file(filsti)\n",
    "\n",
    "    elif filendelse == '.gpkg':\n",
    "        return gpd.read_file(filsti, driver='GPKG')\n",
    "\n",
    "    elif filendelse == '.csv':\n",
    "        return konverter_csv(filsti)\n",
    "\n",
    "    return None\n",
    "\n",
    "def konverter_til_geoparquet(kildefilsti, målmappesti=None):\n",
    "    \"\"\"Konverterer ulike geografiske formater til GeoParquet-format\"\"\"\n",
    "    # Få filendelse\n",
    "    filendelse = os.path.splitext(kildefilsti)[1].lower()\n",
    "\n",
    "    # Bestem målfilsti\n",
    "    målfilsti = lag_målfilsti(kildefilsti, målmappesti)\n",
    "\n",
    "    # Sørg for at målmappen eksisterer\n",
    "    opprett_mappe(målfilsti)\n",
    "\n",
    "    try:\n",
    "        # Konverter filen basert på filtype\n",
    "        gdf = konverter_fil_basert_på_type(kildefilsti, filendelse)\n",
    "\n",
    "        # Hvis vi har en gyldig geodataframe, lagre som GeoParquet\n",
    "        if gdf is not None:\n",
    "            gdf.to_parquet(målfilsti)\n",
    "            return målfilsti\n",
    "    except Exception as e:\n",
    "        print(f\"Feil ved konvertering av {kildefilsti}: {e}\")\n",
    "\n",
    "    return False"
   ],
   "id": "453979dd35596cd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Let etter og identifiserer geografiske datafiler som ennå ikke er blitt konvertert til GeoParquet-format",
   "id": "8c1fbac795cb445e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T12:13:30.041743Z",
     "start_time": "2025-03-07T12:13:30.025644Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 5,
   "source": [
    "def hent_støttede_formater():\n",
    "    \"\"\"Returnerer liste over støttede filformater\"\"\"\n",
    "    return ['.parquet', '.geojson', '.json', '.shp', '.gpkg', '.csv']\n",
    "\n",
    "def hent_konverterte_filer(prosessert_mappesti):\n",
    "    \"\"\"Henter ut alle allerede konverterte filer\"\"\"\n",
    "    konverterte_filer = set()\n",
    "    if not os.path.exists(prosessert_mappesti):\n",
    "        return konverterte_filer\n",
    "\n",
    "    for root, _, filer in os.walk(prosessert_mappesti):\n",
    "        for fil in filer:\n",
    "            if fil.endswith('.parquet'):\n",
    "                base_navn = os.path.splitext(fil)[0]\n",
    "                konverterte_filer.add(base_navn)\n",
    "\n",
    "    return konverterte_filer\n",
    "\n",
    "def les_konverteringslogg(konverteringslogg_sti):\n",
    "    \"\"\"Leser konverteringsloggen fra fil\"\"\"\n",
    "    if not konverteringslogg_sti or not os.path.exists(konverteringslogg_sti):\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        with open(konverteringslogg_sti, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def er_fil_gyldig_for_konvertering(filsti, base_navn, filendelse, støttede_formater):\n",
    "    \"\"\"Sjekker om en fil er gyldig for konvertering\"\"\"\n",
    "    # Sjekk om filen har et støttet format\n",
    "    if filendelse not in støttede_formater:\n",
    "        return False\n",
    "\n",
    "    # Parquet-filer trenger ekstra sjekk\n",
    "    if filendelse == '.parquet':\n",
    "        # Ikke ta med filer som allerede er GeoParquet\n",
    "        if er_geoparquet(filsti):\n",
    "            return False\n",
    "        # Ikke ta med filer som allerede har _geo suffix\n",
    "        if base_navn.endswith('_geo'):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def trenger_fil_konvertering(filsti, base_navn, konverterte_filer, konverterte_logger):\n",
    "    \"\"\"Sjekker om en fil trenger konvertering basert på konverteringshistorikk\"\"\"\n",
    "    # Sjekk om filen allerede er konvertert\n",
    "    if base_navn in konverterte_filer:\n",
    "        return False\n",
    "\n",
    "    # Sjekk om filen har endret seg siden sist konvertering\n",
    "    if base_navn in konverterte_logger:\n",
    "        sist_endret_tid = os.path.getmtime(filsti)\n",
    "        sist_konvertert_tid = konverterte_logger[base_navn].get('tidspunkt', 0)\n",
    "        if sist_endret_tid <= sist_konvertert_tid:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def finn_nye_filer(rå_mappesti, prosessert_mappesti, konverteringslogg_sti=None):\n",
    "    \"\"\"Finner filer som ikke har blitt konvertert ennå\"\"\"\n",
    "    støttede_formater = hent_støttede_formater()\n",
    "    konverterte_filer = hent_konverterte_filer(prosessert_mappesti)\n",
    "    konverterte_logger = les_konverteringslogg(konverteringslogg_sti)\n",
    "\n",
    "    nye_filer = []\n",
    "\n",
    "    for root, _, filer in os.walk(rå_mappesti):\n",
    "        for fil in filer:\n",
    "            filsti = os.path.join(root, fil)\n",
    "            filendelse = os.path.splitext(fil)[1].lower()\n",
    "            base_navn = os.path.splitext(fil)[0]\n",
    "\n",
    "            # Sjekk om filen er gyldig for konvertering\n",
    "            if not er_fil_gyldig_for_konvertering(filsti, base_navn, filendelse, støttede_formater):\n",
    "                continue\n",
    "\n",
    "            # Sjekk om filen trenger konvertering\n",
    "            if trenger_fil_konvertering(filsti, base_navn, konverterte_filer, konverterte_logger):\n",
    "                nye_filer.append(filsti)\n",
    "\n",
    "    return nye_filer"
   ],
   "id": "1ff928da1d3bb59c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Registrer informasjon om nylig konverterte geografiske datafiler i en loggfil",
   "id": "2db340802c78f883"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T12:13:30.094392Z",
     "start_time": "2025-03-07T12:13:30.083855Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": [
    "def les_eksisterende_logg(konverteringslogg_sti):\n",
    "    \"\"\"Leser inn eksisterende konverteringslogg\"\"\"\n",
    "    if not os.path.exists(konverteringslogg_sti):\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        with open(konverteringslogg_sti, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def lag_logginnslag(fil, målfilsti):\n",
    "    \"\"\"Lager et nytt logginnslag for en konvertert fil\"\"\"\n",
    "    base_navn = os.path.splitext(os.path.basename(fil))[0]\n",
    "    nå = datetime.datetime.now()\n",
    "\n",
    "    return {\n",
    "        base_navn: {\n",
    "            'kildesti': fil,\n",
    "            'målsti': målfilsti,\n",
    "            'tidspunkt': nå.timestamp(),\n",
    "            'dato': nå.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "    }\n",
    "\n",
    "def lagre_logg(konverteringslogg_sti, loggdata):\n",
    "    \"\"\"Lagrer konverteringslogg til fil\"\"\"\n",
    "    with open(konverteringslogg_sti, 'w') as f:\n",
    "        json.dump(loggdata, f, indent=2)\n",
    "\n",
    "def oppdater_konverteringslogg(konverteringslogg_sti, fil, målfilsti):\n",
    "    \"\"\"Oppdaterer konverteringsloggen med ny filinfo\"\"\"\n",
    "    # Last inn eksisterende logg\n",
    "    konverterte_logger = les_eksisterende_logg(konverteringslogg_sti)\n",
    "\n",
    "    # Lag og legg til nytt logginnslag\n",
    "    nytt_innslag = lag_logginnslag(fil, målfilsti)\n",
    "    konverterte_logger.update(nytt_innslag)\n",
    "\n",
    "    # Lagre oppdatert logg\n",
    "    lagre_logg(konverteringslogg_sti, konverterte_logger)"
   ],
   "id": "2766de870fb052fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6. Ser gjennom en mappestruktur, identifiserer geografiske datafiler, konverterer dem til GeoParquet-format hvis de ikke allerede er det, og lager en detaljert rapport over resultatet.",
   "id": "ee2dca6eb7fafd8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:35:35.912101Z",
     "start_time": "2025-03-09T13:35:35.903687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def valider_rotmappe(rotmappesti):\n",
    "    \"\"\"Validerer at rotmappen eksisterer\"\"\"\n",
    "    if not os.path.exists(rotmappesti):\n",
    "        print(f\"FEIL: Katalogen '{rotmappesti}' eksisterer ikke.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def oppsett_mappestier(rotmappesti, opprett_struktur):\n",
    "    \"\"\"Setter opp og returnerer nødvendige mappestier\"\"\"\n",
    "    mappestruktur = None\n",
    "    rå_mappesti = rotmappesti\n",
    "    prosessert_mappesti = rotmappesti\n",
    "\n",
    "    # Opprett mappestruktur hvis ønsket\n",
    "    if opprett_struktur:\n",
    "        mappestruktur = opprett_mappestruktur(rotmappesti)\n",
    "        rå_mappesti = mappestruktur['raw']\n",
    "        prosessert_mappesti = mappestruktur['processed']\n",
    "        print(f\"Opprettet mappestruktur:\\n- Raw: {rå_mappesti}\\n- Processed: {prosessert_mappesti}\")\n",
    "\n",
    "    return {\n",
    "        \"mappestruktur\": mappestruktur,\n",
    "        \"rå_mappesti\": rå_mappesti,\n",
    "        \"prosessert_mappesti\": prosessert_mappesti,\n",
    "        \"konverteringslogg_sti\": os.path.join(rotmappesti, 'conversion_log.json')\n",
    "    }\n",
    "\n",
    "def konverter_filer(nye_filer, prosessert_mappesti, konverteringslogg_sti):\n",
    "    \"\"\"Konverterer filer og oppdaterer logg\"\"\"\n",
    "    resultater = {\n",
    "        \"konvertert\": [],\n",
    "        \"feilet\": []\n",
    "    }\n",
    "\n",
    "    for filsti in nye_filer:\n",
    "        # Konverter filen\n",
    "        målfilsti = konverter_til_geoparquet(filsti, prosessert_mappesti)\n",
    "\n",
    "        if målfilsti:\n",
    "            resultater[\"konvertert\"].append(filsti)\n",
    "            oppdater_konverteringslogg(konverteringslogg_sti, filsti, målfilsti)\n",
    "        else:\n",
    "            resultater[\"feilet\"].append(filsti)\n",
    "\n",
    "    return resultater\n",
    "\n",
    "def finn_eksisterende_geoparquet(rå_mappesti, alle_filer):\n",
    "    \"\"\"Finner eksisterende GeoParquet-filer\"\"\"\n",
    "    allerede_geoparquet = []\n",
    "\n",
    "    for root, _, filer in os.walk(rå_mappesti):\n",
    "        for fil in filer:\n",
    "            if fil.endswith('.parquet'):\n",
    "                filsti = os.path.join(root, fil)\n",
    "                if er_geoparquet(filsti) and filsti not in alle_filer:\n",
    "                    allerede_geoparquet.append(filsti)\n",
    "\n",
    "    return allerede_geoparquet\n",
    "\n",
    "def skriv_oppsummering(rotmappesti, mappestier, resultater):\n",
    "    \"\"\"Skriver oppsummering av konverteringsprosessen\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"OPPSUMMERING\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Katalog: {rotmappesti}\")\n",
    "\n",
    "    if mappestier[\"mappestruktur\"]:\n",
    "        print(f\"Mappestruktur: Raw={mappestier['rå_mappesti']}, Processed={mappestier['prosessert_mappesti']}\")\n",
    "\n",
    "    totalt_antall = len(resultater[\"alle_filer\"])\n",
    "    antall_allerede_geo = len(resultater[\"allerede_geoparquet\"])\n",
    "    antall_konvertert = len(resultater[\"konvertert\"])\n",
    "    antall_feilet = len(resultater[\"feilet\"])\n",
    "\n",
    "    print(f\"Totalt antall geografiske filer funnet: {totalt_antall}\")\n",
    "    print(f\"Antall parquet-filer som allerede var GeoParquet: {antall_allerede_geo}\")\n",
    "    print(f\"Antall filer konvertert til GeoParquet: {antall_konvertert}\")\n",
    "    print(f\"Antall filer som ikke kunne konverteres: {antall_feilet}\")\n",
    "\n",
    "    if resultater[\"konvertert\"]:\n",
    "        print(\"\\nKonverterte filer:\")\n",
    "        for fil in resultater[\"konvertert\"]:\n",
    "            print(f\"- {fil}\")\n",
    "\n",
    "    if resultater[\"feilet\"]:\n",
    "        print(\"\\nFiler som ikke kunne konverteres:\")\n",
    "        for fil in resultater[\"feilet\"]:\n",
    "            print(f\"- {fil}\")\n",
    "\n",
    "def behandle_alle_filer_i_mappe(rotmappesti, opprett_struktur=True):\n",
    "    \"\"\"Behandler alle geografiske filer i angitt mappe og konverterer til GeoParquet.\"\"\"\n",
    "    # Validering\n",
    "    if not valider_rotmappe(rotmappesti):\n",
    "        return None\n",
    "\n",
    "    # Oppsett av mappestruktur\n",
    "    mappestier = oppsett_mappestier(rotmappesti, opprett_struktur)\n",
    "\n",
    "    # Finn nye filer som trenger konvertering\n",
    "    nye_filer = finn_nye_filer(\n",
    "        mappestier[\"rå_mappesti\"],\n",
    "        mappestier[\"prosessert_mappesti\"],\n",
    "        mappestier[\"konverteringslogg_sti\"]\n",
    "    )\n",
    "\n",
    "    # Initialiser resultater\n",
    "    resultater = {\n",
    "        \"allerede_geoparquet\": [],\n",
    "        \"konvertert\": [],\n",
    "        \"feilet\": [],\n",
    "        \"alle_filer\": nye_filer.copy()\n",
    "    }\n",
    "\n",
    "    # Konverter filer\n",
    "    konverteringsresultater = konverter_filer(\n",
    "        nye_filer,\n",
    "        mappestier[\"prosessert_mappesti\"],\n",
    "        mappestier[\"konverteringslogg_sti\"]\n",
    "    )\n",
    "    resultater[\"konvertert\"] = konverteringsresultater[\"konvertert\"]\n",
    "    resultater[\"feilet\"] = konverteringsresultater[\"feilet\"]\n",
    "\n",
    "    # Finn allerede eksisterende GeoParquet-filer\n",
    "    resultater[\"allerede_geoparquet\"] = finn_eksisterende_geoparquet(\n",
    "        mappestier[\"rå_mappesti\"],\n",
    "        resultater[\"alle_filer\"]\n",
    "    )\n",
    "    resultater[\"alle_filer\"].extend(resultater[\"allerede_geoparquet\"])\n",
    "\n",
    "    # Skriv oppsummering\n",
    "    skriv_oppsummering(rotmappesti, mappestier, resultater)\n",
    "\n",
    "    return resultater\n",
    "\n",
    "# Angi rotmappen som skal behandles\n",
    "resultater = behandle_alle_filer_i_mappe(ROTMAPPE, opprett_struktur=True)"
   ],
   "id": "7c63aac0595a3bd8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Filtering\n",
    "Leser, filtrere og analysere geografiske data fra en GeoParquet-fil basert på gitte kriterier"
   ],
   "id": "a4732d2aef969375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:50:10.643275Z",
     "start_time": "2025-03-09T13:50:10.625082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MÅ HENTE RIKTIG FIL!\n",
    "\n",
    "# Les geoparquet-filen\n",
    "fil_sti = f\"{ROTMAPPE}/raw/hais_2025-01-01.snappy.parquet\"\n",
    "gdf = gpd.read_parquet(fil_sti)\n",
    "\n",
    "# Filtrering basert på attributt/kolonne\n",
    "if 'date_time_utc' in gdf.columns:\n",
    "    filtrert_på_dato = gdf[gdf['date_time_utc'] >= '2025-01-01 12:00:00']\n",
    "    print(f\"Antall rader etter datofiltrering: {len(filtrert_på_dato)}\")\n",
    "    display(filtrert_på_dato.head())\n",
    "\n",
    "# Filtrering basert på geometri (f.eks. et område)\n",
    "område = box(5.0, 60.0, 11.0, 60.0)\n",
    "innenfor_område = gdf[gdf.geometry.intersects(område)]\n",
    "print(f\"Antall rader innenfor det definerte området: {len(innenfor_område)}\")\n",
    "display(innenfor_område.head())\n",
    "\n",
    "# Kombinert filtrering med flere kriterier\n",
    "if 'attributt' in gdf.columns:\n",
    "    kombinert_filter = gdf[(gdf.geometry.intersects(område)) & (gdf['attributt'] > 10)]\n",
    "    print(f\"Antall rader etter kombinert filtrering: {len(kombinert_filter)}\")\n",
    "    display(kombinert_filter.head())"
   ],
   "id": "a6e2988928bdc97e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROTMAPPE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# MÅ HENTE RIKTIG FIL!\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Les geoparquet-filen\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m fil_sti \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mROTMAPPE\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/raw/hais_2025-01-01.snappy.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m gdf \u001B[38;5;241m=\u001B[39m gpd\u001B[38;5;241m.\u001B[39mread_parquet(fil_sti)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Filtrering basert på attributt/kolonne\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ROTMAPPE' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Funksjoner",
   "id": "13d35301112dd8e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def les_geoparquet(fil_sti):\n",
    "    \"\"\"Leser en GeoParquet-fil og returnerer en GeoDataFrame\"\"\"\n",
    "    return gpd.read_parquet(fil_sti)\n",
    "\n",
    "def filtrer_på_dato(gdf, dato_kolonne, start_dato):\n",
    "    \"\"\"Filtrerer GeoDataFrame basert på dato\"\"\"\n",
    "    if dato_kolonne not in gdf.columns:\n",
    "        print(f\"ADVARSEL: Kolonnen '{dato_kolonne}' finnes ikke i datasettet\")\n",
    "        return gdf\n",
    "\n",
    "    filtrert = gdf[gdf[dato_kolonne] >= start_dato]\n",
    "    print(f\"Antall rader etter datofiltrering: {len(filtrert)}\")\n",
    "    return filtrert\n",
    "\n",
    "def filtrer_på_område(gdf, min_x, min_y, max_x, max_y):\n",
    "    \"\"\"Filtrerer GeoDataFrame basert på et geografisk område\"\"\"\n",
    "    område = box(min_x, min_y, max_x, max_y)\n",
    "    filtrert = gdf[gdf.geometry.intersects(område)]\n",
    "    print(f\"Antall rader innenfor det definerte området: {len(filtrert)}\")\n",
    "    return filtrert\n",
    "\n",
    "def filtrer_på_attributt(gdf, attributt, verdi, operator='større'):\n",
    "    \"\"\"Filtrerer GeoDataFrame basert på et attributt\"\"\"\n",
    "    if attributt not in gdf.columns:\n",
    "        print(f\"ADVARSEL: Kolonnen '{attributt}' finnes ikke i datasettet\")\n",
    "        return gdf\n",
    "\n",
    "    if operator == 'større':\n",
    "        filtrert = gdf[gdf[attributt] > verdi]\n",
    "    elif operator == 'mindre':\n",
    "        filtrert = gdf[gdf[attributt] < verdi]\n",
    "    elif operator == 'lik':\n",
    "        filtrert = gdf[gdf[attributt] == verdi]\n",
    "    else:\n",
    "        print(f\"ADVARSEL: Ukjent operator '{operator}'\")\n",
    "        return gdf\n",
    "\n",
    "    print(f\"Antall rader etter attributtfiltrering: {len(filtrert)}\")\n",
    "    return filtrert\n",
    "\n",
    "def kombiner_filtre(gdf, område_filter=None, dato_filter=None, attributt_filter=None):\n",
    "    \"\"\"Kombinerer flere filtre på en GeoDataFrame\"\"\"\n",
    "    resultat = gdf.copy()\n",
    "\n",
    "    if område_filter:\n",
    "        min_x, min_y, max_x, max_y = område_filter\n",
    "        område = box(min_x, min_y, max_x, max_y)\n",
    "        resultat = resultat[resultat.geometry.intersects(område)]\n",
    "\n",
    "    if dato_filter:\n",
    "        kolonne, start_dato = dato_filter\n",
    "        if kolonne in resultat.columns:\n",
    "            resultat = resultat[resultat[kolonne] >= start_dato]\n",
    "\n",
    "    if attributt_filter:\n",
    "        kolonne, verdi, operator = attributt_filter\n",
    "        if kolonne in resultat.columns:\n",
    "            if operator == 'større':\n",
    "                resultat = resultat[resultat[kolonne] > verdi]\n",
    "            elif operator == 'mindre':\n",
    "                resultat = resultat[resultat[kolonne] < verdi]\n",
    "            elif operator == 'lik':\n",
    "                resultat = resultat[resultat[kolonne] == verdi]\n",
    "\n",
    "    print(f\"Antall rader etter kombinert filtrering: {len(resultat)}\")\n",
    "    return resultat\n",
    "\n",
    "# Eksempel på bruk:\n",
    "def analyser_ais_data():\n",
    "    # Konstanter\n",
    "    ROTMAPPE = \"/sti/til/data\"\n",
    "    # MÅ HENTE RIKTIG FIL!\n",
    "    fil_sti = f\"{ROTMAPPE}/raw/hais_2025-01-01.snappy.parquet\"\n",
    "\n",
    "    # Les data\n",
    "    gdf = les_geoparquet(fil_sti)\n",
    "    print(f\"Totalt antall rader i datasettet: {len(gdf)}\")\n",
    "\n",
    "    # Enkle filtreringer\n",
    "    gdf_dato = filtrer_på_dato(gdf, 'date_time_utc', '2025-01-01 12:00:00')\n",
    "    gdf_område = filtrer_på_område(gdf, 5.0, 60.0, 11.0, 60.0)\n",
    "\n",
    "    # Kombinert filtrering\n",
    "    gdf_kombinert = kombiner_filtre(\n",
    "        gdf,\n",
    "        område_filter=(5.0, 60.0, 11.0, 60.0),\n",
    "        attributt_filter=('attributt', 10, 'større')\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'original': gdf,\n",
    "        'dato_filtrert': gdf_dato,\n",
    "        'område_filtrert': gdf_område,\n",
    "        'kombinert_filtrert': gdf_kombinert\n",
    "    }"
   ],
   "id": "3a22607fec5e1928"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Innledende analyse av datasett",
   "id": "10e7e8991d1f3456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Oppsett og lesing av data\n",
    "ROTMAPPE = \"/sti/til/data\"\n",
    "fil_sti = f\"{ROTMAPPE}/raw/hais_2025-01-01.snappy.parquet\"\n",
    "gdf = les_geoparquet(fil_sti)\n",
    "\n",
    "# Vise grunnleggende datasettinfo\n",
    "print(f\"Totalt antall rader i datasettet: {len(gdf)}\")\n",
    "print(f\"Kolonner i datasettet: {list(gdf.columns)}\")\n",
    "gdf.head()"
   ],
   "id": "78af06d802df5b0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Tidsbasert analyse",
   "id": "b90a086db73a7a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filtrere på dato\n",
    "gdf_dato = filtrer_på_dato(gdf, 'date_time_utc', '2025-01-01 12:00:00')\n",
    "gdf_dato.head()"
   ],
   "id": "ec24d0f7f4bc311"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Geografisk analyse",
   "id": "54c687677bc1b834"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filtrere på geografisk område\n",
    "gdf_område = filtrer_på_område(gdf, 5.0, 60.0, 11.0, 60.0)\n",
    "\n",
    "# Kanskje vise et kart med området og punktene\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "gdf.plot(ax=ax, color='gray', alpha=0.3, markersize=5)\n",
    "gdf_område.plot(ax=ax, color='red', markersize=5)\n",
    "ax.set_title('Geografisk filtrering')\n",
    "plt.show()"
   ],
   "id": "4845c42b280f7d82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Kombinert analyse",
   "id": "bb0ea51ea11d58de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Kombinert filtrering for mer spesifikke analyseformål\n",
    "gdf_kombinert = kombiner_filtre(\n",
    "    gdf,\n",
    "    område_filter=(5.0, 60.0, 11.0, 60.0),\n",
    "    attributt_filter=('attributt', 10, 'større')\n",
    ")\n",
    "gdf_kombinert.head()"
   ],
   "id": "2a6863ef0a0e52fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Partisjonering\n",
    "Partisjonerer geografiske skipstrafikkdata basert på tid og skipstype"
   ],
   "id": "f99835eaa749eee4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Konstanter",
   "id": "313f495fbebd14ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ROTMAPPE = \"./data\"\n",
    "PARTISJON_MAPPE_HOUR = os.path.join(ROTMAPPE, \"partisjonert_time\")\n",
    "PARTISJON_MAPPE_MIN = os.path.join(ROTMAPPE, \"partisjonert_10min\")"
   ],
   "id": "69d214f68441f1e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Funksjoner",
   "id": "fb67c8c0f6c23f7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def opprett_mappe(mappesti):\n",
    "    \"\"\"Oppretter en mappe hvis den ikke eksisterer\"\"\"\n",
    "    os.makedirs(mappesti, exist_ok=True)\n",
    "    return mappesti\n",
    "\n",
    "def lag_time_partisjon(data, målfolder):\n",
    "    \"\"\"Partisjonerer geodata basert på time og skipstype\"\"\"\n",
    "    # Lag en kopi for å unngå SettingWithCopyWarning\n",
    "    data_for_partisjonering = data.copy()\n",
    "\n",
    "    # Bruk .loc for å legge til time-kolonnen\n",
    "    data_for_partisjonering.loc[:, 'time'] = data_for_partisjonering['date_time_utc'].dt.hour\n",
    "\n",
    "    # Opprett hovedmappen\n",
    "    opprett_mappe(målfolder)\n",
    "\n",
    "    antall_filer = 0\n",
    "    antall_rader = 0\n",
    "\n",
    "    # Partisjonering basert på time og ship_type\n",
    "    for time, gruppe_time in data_for_partisjonering.groupby('time'):\n",
    "        time_mappe = os.path.join(målfolder, f\"time={time:02d}\")\n",
    "        opprett_mappe(time_mappe)\n",
    "\n",
    "        for ship_type, gruppe_final in gruppe_time.groupby('ship_type'):\n",
    "            skip_mappe = os.path.join(time_mappe, f\"ship_type={ship_type}\")\n",
    "            opprett_mappe(skip_mappe)\n",
    "\n",
    "            # Bruk en kopi av dataene\n",
    "            data_å_lagre = gruppe_final.copy()\n",
    "\n",
    "            # Fjern partisjoneringskolonnen før lagring\n",
    "            fil_sti = os.path.join(skip_mappe, f\"data.parquet\")\n",
    "            data_å_lagre.drop('time', axis=1).to_parquet(fil_sti)\n",
    "\n",
    "            print(f\"Skrevet {len(gruppe_final)} rader til {fil_sti}\")\n",
    "            antall_filer += 1\n",
    "            antall_rader += len(gruppe_final)\n",
    "\n",
    "    return {'antall_filer': antall_filer, 'antall_rader': antall_rader}\n",
    "\n",
    "def lag_10min_partisjon(data, målfolder):\n",
    "    \"\"\"Partisjonerer geodata basert på 10-minutters intervaller og skipstype\"\"\"\n",
    "    # Lag en kopi for å unngå SettingWithCopyWarning\n",
    "    data_for_partisjonering = data.copy()\n",
    "\n",
    "    # Bruk .loc for å legge til 10-minutters intervall kolonne\n",
    "    # Dette gir intervaller 0-143 for hele dagen (144 intervaller på 10 minutter)\n",
    "    data_for_partisjonering.loc[:, 'minuttgruppe'] = (\n",
    "        data_for_partisjonering['date_time_utc'].dt.hour * 6 +\n",
    "        data_for_partisjonering['date_time_utc'].dt.minute // 10\n",
    "    )\n",
    "\n",
    "    # Opprett hovedmappen\n",
    "    opprett_mappe(målfolder)\n",
    "\n",
    "    antall_filer = 0\n",
    "    antall_rader = 0\n",
    "\n",
    "    # Partisjonering basert på minuttgruppe og ship_type\n",
    "    for minuttgruppe, gruppe_minutt in data_for_partisjonering.groupby('minuttgruppe'):\n",
    "        # Konverter minuttgruppe til time og minutt for mappe-strukturen\n",
    "        time = minuttgruppe // 6\n",
    "        minutt = (minuttgruppe % 6) * 10\n",
    "\n",
    "        # Lag en lesbar mappestruktur (time_minutt=HH_MM)\n",
    "        minutt_mappe = os.path.join(målfolder, f\"time_minutt={time:02d}_{minutt:02d}\")\n",
    "        opprett_mappe(minutt_mappe)\n",
    "\n",
    "        for ship_type, gruppe_final in gruppe_minutt.groupby('ship_type'):\n",
    "            skip_mappe = os.path.join(minutt_mappe, f\"ship_type={ship_type}\")\n",
    "            opprett_mappe(skip_mappe)\n",
    "\n",
    "            # Bruk en kopi av dataene\n",
    "            data_å_lagre = gruppe_final.copy()\n",
    "\n",
    "            # Fjern partisjoneringskolonnen før lagring\n",
    "            fil_sti = os.path.join(skip_mappe, f\"data.parquet\")\n",
    "            data_å_lagre.drop('minuttgruppe', axis=1).to_parquet(fil_sti)\n",
    "\n",
    "            print(f\"Skrevet {len(gruppe_final)} rader til {fil_sti}\")\n",
    "            antall_filer += 1\n",
    "            antall_rader += len(gruppe_final)\n",
    "\n",
    "    return {'antall_filer': antall_filer, 'antall_rader': antall_rader}\n",
    "\n",
    "def les_partisjonerte_data_for_måned(rotmappesti, ønsket_måned):\n",
    "    \"\"\"Leser partisjonerte data for en spesifikk måned\"\"\"\n",
    "    måned_sti = os.path.join(rotmappesti, f\"år_måned={ønsket_måned}\")\n",
    "\n",
    "    if not os.path.exists(måned_sti):\n",
    "        print(f\"Ingen mappe funnet for {ønsket_måned}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Leser data for {ønsket_måned}...\")\n",
    "    # Finn alle geoparquet-filer i denne månedens mappe (inkludert undermapper)\n",
    "    filer = glob.glob(os.path.join(måned_sti, \"**/*.parquet\"), recursive=True)\n",
    "\n",
    "    # Les og kombiner alle filene\n",
    "    dataframes = []\n",
    "    for fil in filer:\n",
    "        gdf = gpd.read_parquet(fil)\n",
    "        dataframes.append(gdf)\n",
    "\n",
    "    if not dataframes:\n",
    "        print(f\"Ingen data funnet for {ønsket_måned}\")\n",
    "        return None\n",
    "\n",
    "    månedsdata = pd.concat(dataframes)\n",
    "    print(f\"Hentet {len(månedsdata)} rader for {ønsket_måned}\")\n",
    "    return månedsdata\n",
    "\n",
    "def les_partisjonerte_data_for_skipstype(rotmappesti, ønsket_skipstype):\n",
    "    \"\"\"Leser partisjonerte data for en spesifikk skipstype\"\"\"\n",
    "    skipstype_stier = glob.glob(os.path.join(rotmappesti, f\"**/ship_type={ønsket_skipstype}/*.parquet\"), recursive=True)\n",
    "\n",
    "    if not skipstype_stier:\n",
    "        print(f\"Ingen data funnet for skipstype {ønsket_skipstype}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Leser data for skipstype {ønsket_skipstype}...\")\n",
    "    skipstype_dataframes = []\n",
    "    for fil in skipstype_stier:\n",
    "        gdf = gpd.read_parquet(fil)\n",
    "        skipstype_dataframes.append(gdf)\n",
    "\n",
    "    skipstype_data = pd.concat(skipstype_dataframes)\n",
    "    print(f\"Hentet {len(skipstype_data)} rader for skipstype {ønsket_skipstype}\")\n",
    "    return skipstype_data"
   ],
   "id": "504d52a122b881bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Dataforberedelse",
   "id": "4e14ad9e18438421"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Les inn datasettet\n",
    "fil_sti = f\"{ROTMAPPE}/raw/hais_2025-01-01.snappy.parquet\"\n",
    "gdf = gpd.read_parquet(fil_sti)\n",
    "print(f\"Totalt antall rader i datasettet: {len(gdf)}\")\n",
    "\n",
    "# Filtrer data til et bestemt geografisk område\n",
    "område = box(5.0, 60.0, 11.0, 60.0)\n",
    "innenfor_område = gdf[gdf.geometry.intersects(område)]\n",
    "print(f\"Antall rader innenfor området: {len(innenfor_område)}\")\n",
    "\n",
    "# Vis første rader\n",
    "display(innenfor_område.head())"
   ],
   "id": "215e3095dce2d537"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Timebasert partisjonering",
   "id": "abda49ba0a7e4fe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Partisjonering basert på time\n",
    "resultat_time = lag_time_partisjon(innenfor_område, PARTISJON_MAPPE_HOUR)\n",
    "\n",
    "# Oppsummering\n",
    "print(f\"\\nTimebasert partisjonering fullført:\")\n",
    "print(f\"- Antall filer opprettet: {resultat_time['antall_filer']}\")\n",
    "print(f\"- Totalt antall rader lagret: {resultat_time['antall_rader']}\")"
   ],
   "id": "fc1a04805943ac80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. 10-minutters partisjonering",
   "id": "d3d7c2f7e2d2729b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Partisjonering basert på 10-minutters intervaller\n",
    "resultat_10min = lag_10min_partisjon(innenfor_område, PARTISJON_MAPPE_MIN)\n",
    "\n",
    "# Oppsummering\n",
    "print(f\"\\n10-minutters partisjonering fullført:\")\n",
    "print(f\"- Antall filer opprettet: {resultat_10min['antall_filer']}\")\n",
    "print(f\"- Totalt antall rader lagret: {resultat_10min['antall_rader']}\")"
   ],
   "id": "e689a8bd14e6ff2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6. Les partisjonert data for en spesifikk måned",
   "id": "14ef8f1fbc3deb27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Definer ønsket måned\n",
    "ønsket_måned = \"2025-01\"\n",
    "\n",
    "# Les data for den valgte måneden\n",
    "månedsdata = les_partisjonerte_data_for_måned(PARTISJON_MAPPE_HOUR, ønsket_måned)\n",
    "\n",
    "# Vis data hvis tilgjengelig\n",
    "if månedsdata is not None:\n",
    "    display(månedsdata.head())\n",
    "\n",
    "    # Lag en enkel visualisering\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    månedsdata.plot(ax=ax, column='ship_type', cmap='viridis', legend=True)\n",
    "    ax.set_title(f'Skipstrafikk i {ønsket_måned}')\n",
    "    plt.show()"
   ],
   "id": "999f3a9d9fcdd5ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. Les partisjonerte data for en spesifikk skipstype",
   "id": "ec515731ae959bf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Definer ønsket skipstype\n",
    "ønsket_skipstype = 70\n",
    "\n",
    "# Les data for den valgte skipstypen\n",
    "skipstypedata = les_partisjonerte_data_for_skipstype(PARTISJON_MAPPE_HOUR, ønsket_skipstype)\n",
    "\n",
    "# Vis data hvis tilgjengelig\n",
    "if skipstypedata is not None:\n",
    "    display(skipstypedata.head())\n",
    "\n",
    "    # Visualiser dataene\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    skipstypedata.plot(ax=ax, color='red', alpha=0.5)\n",
    "    ax.set_title(f'Posisjon for skipstype {ønsket_skipstype}')\n",
    "    plt.show()\n",
    "\n",
    "    # Lagre resultatene til en fil\n",
    "    # skipstypedata.to_parquet(f\"{ROTMAPPE}/resultater/skipstype_{ønsket_skipstype}.parquet\")"
   ],
   "id": "c7b1464abeb33364"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simulering av datastrømming",
   "id": "9c3d9653bf6fd8b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Simulert datastrømming med visualisering\n",
    "\n",
    "# Finn alle minutt-mapper sortert kronologisk\n",
    "alle_intervaller = sorted([d for d in os.listdir(PARTISJON_MAPPE_MIN) if d.startswith(\"time_minutt=\")])\n",
    "\n",
    "# Funksjon for å lage et kart med skipsbevegelser\n",
    "def vis_skip_på_kart(data, tidspunkt):\n",
    "    # Konverter til WGS84 koordinatsystem hvis nødvendig\n",
    "    if data.crs and data.crs != \"EPSG:4326\":\n",
    "        data = data.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Beregn senterpunkt for kartet\n",
    "    midpoint_lat = data.geometry.centroid.y.mean()\n",
    "    midpoint_lon = data.geometry.centroid.x.mean()\n",
    "\n",
    "    # Opprett et kart sentrert på dataenes midtpunkt\n",
    "    m = folium.Map(location=[midpoint_lat, midpoint_lon], zoom_start=10)\n",
    "\n",
    "    # Legg til en tittel\n",
    "    tittel_html = f'''\n",
    "    <h3 align=\"center\" style=\"font-size:16px\"><b>Skipsbevegelser: {tidspunkt}</b></h3>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(tittel_html))\n",
    "\n",
    "    # Fargekoding basert på skipstype\n",
    "    ship_type_colors = {\n",
    "        30: 'blue',      # Fiskefartøy\n",
    "        31: 'green',     # Slepebåt\n",
    "        52: 'red',       # Passasjerskip\n",
    "        60: 'purple',    # Passasjerskip\n",
    "        70: 'orange',    # Lasteskip\n",
    "        80: 'darkblue',  # Tankskip\n",
    "        # Legg til flere skipstyper etter behov\n",
    "    }\n",
    "\n",
    "    # Legg til hvert skip på kartet\n",
    "    for idx, row in data.iterrows():\n",
    "        # Bestem farge basert på skipstype\n",
    "        color = ship_type_colors.get(row['ship_type'], 'gray')\n",
    "\n",
    "        # Hent koordinater\n",
    "        coords = (row.geometry.y, row.geometry.x)\n",
    "\n",
    "        # Lag popup-info\n",
    "        popup_text = f\"\"\"\n",
    "        <b>Skip:</b> {row['ship_name']}<br>\n",
    "        <b>MMSI:</b> {row['mmsi']}<br>\n",
    "        <b>Type:</b> {row['ship_type']}<br>\n",
    "        <b>Hastighet:</b> {row['speed_over_ground']} knop<br>\n",
    "        <b>Kurs:</b> {row['course_over_ground']}°<br>\n",
    "        <b>Tidspunkt:</b> {row['date_time_utc']}\n",
    "        \"\"\"\n",
    "\n",
    "        # Legg til markør med retningspil\n",
    "        folium.Marker(\n",
    "            coords,\n",
    "            popup=folium.Popup(popup_text, max_width=300),\n",
    "            icon=folium.Icon(color=color, icon='ship', prefix='fa'),\n",
    "            tooltip=f\"{row['ship_name']} ({row['mmsi']})\"\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Tegn retningspil hvis kurs er tilgjengelig\n",
    "        if not pd.isna(row['course_over_ground']):\n",
    "            folium.RegularPolygonMarker(\n",
    "                coords,\n",
    "                fill_color=color,\n",
    "                number_of_sides=3,\n",
    "                radius=8,\n",
    "                rotation=row['course_over_ground'],\n",
    "                fill_opacity=0.6,\n",
    "                color='black',\n",
    "                weight=1\n",
    "            ).add_to(m)\n",
    "\n",
    "    # Legg til tegnforklaring\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed;\n",
    "                bottom: 50px; right: 50px; width: 150px; height: 160px;\n",
    "                border:2px solid grey; z-index:9999; font-size:12px;\n",
    "                background-color: white; padding: 10px;\n",
    "                border-radius: 5px;\">\n",
    "    <b>Skipstyper:</b><br>\n",
    "    '''\n",
    "\n",
    "    for ship_type, color in ship_type_colors.items():\n",
    "        legend_html += f'<i class=\"fa fa-ship\" style=\"color:{color}\"></i> Type {ship_type}<br>'\n",
    "\n",
    "    legend_html += '</div>'\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Returner kartet\n",
    "    return m\n",
    "\n",
    "# Simuler datastrømming med visualisering\n",
    "print(\"\\nSimulerer datastrømming med visualisering...\")\n",
    "for intervall_dir in alle_intervaller:\n",
    "    # Hent time og minutt fra mappenavnet\n",
    "    match = re.search(r\"time_minutt=(\\d{2})_(\\d{2})\", intervall_dir)\n",
    "    if match:\n",
    "        time, minutt = match.groups()\n",
    "        tidspunkt = f\"{time}:{minutt}\"\n",
    "\n",
    "        intervall_sti = os.path.join(PARTISJON_MAPPE_MIN, intervall_dir)\n",
    "        print(f\"\\nProsesserer data for {tidspunkt}...\")\n",
    "\n",
    "        # Finn alle geoparquet-filer for dette intervallet\n",
    "        filer = glob.glob(os.path.join(intervall_sti, \"**/*.parquet\"), recursive=True)\n",
    "\n",
    "        # Les og bearbeid hver fil\n",
    "        intervall_data = []\n",
    "        for fil in filer:\n",
    "            gdf = gpd.read_parquet(fil)\n",
    "            intervall_data.append(gdf)\n",
    "\n",
    "        if intervall_data:\n",
    "            samlet_data = pd.concat(intervall_data)\n",
    "            print(f\"Kl. {tidspunkt}: Lastet {len(samlet_data)} rader fra {len(filer)} filer\")\n",
    "\n",
    "            # Vis statistikker\n",
    "            print(f\"  Gjennomsnittlig hastighet (SOG): {samlet_data['speed_over_ground'].mean():.2f}\")\n",
    "            print(f\"  Antall unike skip: {samlet_data['mmsi'].nunique()}\")\n",
    "\n",
    "            # Opprett og vis kart\n",
    "            kart = vis_skip_på_kart(samlet_data, f\"Kl. {tidspunkt}\")\n",
    "\n",
    "            # Lagre kartet til en HTML-fil\n",
    "            # kart_filnavn = f\"kart_{time}_{minutt}.html\"\n",
    "            # kart.save(kart_filnavn)\n",
    "            # print(f\"  Kart lagret som {kart_filnavn}\")\n",
    "\n",
    "            display(kart)\n",
    "\n",
    "        else:\n",
    "            print(f\"Ingen data funnet for kl. {tidspunkt}\")\n",
    "\n",
    "        # Simuler tid mellom intervaller\n",
    "        time_module.sleep(0.5)\n",
    "\n",
    "print(\"\\nDatastrømming komplett!\")"
   ],
   "id": "3bc58bdf1671a9f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Konstanter",
   "id": "28a27e0802a781bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "PARTISJON_MAPPE_MIN = \"din_partisjon_mappe_her\"",
   "id": "657f33498021f7cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Funksjoner",
   "id": "7123d6eff77d5ba9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def finn_minutt_intervaller(hovedmappe):\n",
    "    \"\"\"Finn alle minutt-mapper sortert kronologisk\"\"\"\n",
    "    return sorted([d for d in os.listdir(hovedmappe) if d.startswith(\"time_minutt=\")])\n",
    "\n",
    "def les_data_for_intervall(intervall_sti):\n",
    "    \"\"\"Les og kombiner alle geoparquet-filer for et gitt intervall\"\"\"\n",
    "    # Finn alle geoparquet-filer for dette intervallet\n",
    "    filer = glob.glob(os.path.join(intervall_sti, \"**/*.parquet\"), recursive=True)\n",
    "\n",
    "    # Les og bearbeid hver fil\n",
    "    intervall_data = []\n",
    "    for fil in filer:\n",
    "        gdf = gpd.read_parquet(fil)\n",
    "        intervall_data.append(gdf)\n",
    "\n",
    "    # Kombiner data hvis noen filer ble funnet\n",
    "    if intervall_data:\n",
    "        return pd.concat(intervall_data), len(filer)\n",
    "    else:\n",
    "        return None, 0\n",
    "\n",
    "def beregn_statistikk(data):\n",
    "    \"\"\"Beregn og returner statistikk for datasettet\"\"\"\n",
    "    return {\n",
    "        \"gjennomsnittlig_hastighet\": data['speed_over_ground'].mean(),\n",
    "        \"antall_unike_skip\": data['mmsi'].nunique(),\n",
    "        \"totalt_antall_rader\": len(data)\n",
    "    }\n",
    "\n",
    "def vis_skip_på_kart(data, tidspunkt):\n",
    "    \"\"\"Opprett et kart med skipsbevegelser\"\"\"\n",
    "    # Konverter til WGS84 koordinatsystem hvis nødvendig\n",
    "    if data.crs and data.crs != \"EPSG:4326\":\n",
    "        data = data.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Beregn senterpunkt for kartet\n",
    "    midpoint_lat = data.geometry.centroid.y.mean()\n",
    "    midpoint_lon = data.geometry.centroid.x.mean()\n",
    "\n",
    "    # Opprett et kart sentrert på dataenes midtpunkt\n",
    "    m = folium.Map(location=[midpoint_lat, midpoint_lon], zoom_start=10)\n",
    "\n",
    "    # Legg til en tittel\n",
    "    tittel_html = f'''\n",
    "    <h3 align=\"center\" style=\"font-size:16px\"><b>Skipsbevegelser: {tidspunkt}</b></h3>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(tittel_html))\n",
    "\n",
    "    # Fargekoding basert på skipstype\n",
    "    ship_type_colors = {\n",
    "        30: 'blue',      # Fiskefartøy\n",
    "        31: 'green',     # Slepebåt\n",
    "        52: 'red',       # Passasjerskip\n",
    "        60: 'purple',    # Passasjerskip\n",
    "        70: 'orange',    # Lasteskip\n",
    "        80: 'darkblue',  # Tankskip\n",
    "        # Legg til flere skipstyper etter behov\n",
    "    }\n",
    "\n",
    "    # Legg til skip på kartet\n",
    "    legg_til_skip_på_kart(m, data, ship_type_colors)\n",
    "\n",
    "    # Legg til tegnforklaring\n",
    "    legg_til_tegnforklaring(m, ship_type_colors)\n",
    "\n",
    "    # Returner kartet\n",
    "    return m\n",
    "\n",
    "def legg_til_skip_på_kart(kart, data, farger):\n",
    "    \"\"\"Legg til hvert skip på kartet med ikoner og retningspiler\"\"\"\n",
    "    for idx, row in data.iterrows():\n",
    "        # Bestem farge basert på skipstype\n",
    "        color = farger.get(row['ship_type'], 'gray')\n",
    "\n",
    "        # Hent koordinater\n",
    "        coords = (row.geometry.y, row.geometry.x)\n",
    "\n",
    "        # Lag popup-info\n",
    "        popup_text = f\"\"\"\n",
    "        <b>Skip:</b> {row['ship_name']}<br>\n",
    "        <b>MMSI:</b> {row['mmsi']}<br>\n",
    "        <b>Type:</b> {row['ship_type']}<br>\n",
    "        <b>Hastighet:</b> {row['speed_over_ground']} knop<br>\n",
    "        <b>Kurs:</b> {row['course_over_ground']}°<br>\n",
    "        <b>Tidspunkt:</b> {row['date_time_utc']}\n",
    "        \"\"\"\n",
    "\n",
    "        # Legg til markør med retningspil\n",
    "        folium.Marker(\n",
    "            coords,\n",
    "            popup=folium.Popup(popup_text, max_width=300),\n",
    "            icon=folium.Icon(color=color, icon='ship', prefix='fa'),\n",
    "            tooltip=f\"{row['ship_name']} ({row['mmsi']})\"\n",
    "        ).add_to(kart)\n",
    "\n",
    "        # Tegn retningspil hvis kurs er tilgjengelig\n",
    "        if not pd.isna(row['course_over_ground']):\n",
    "            folium.RegularPolygonMarker(\n",
    "                coords,\n",
    "                fill_color=color,\n",
    "                number_of_sides=3,\n",
    "                radius=8,\n",
    "                rotation=row['course_over_ground'],\n",
    "                fill_opacity=0.6,\n",
    "                color='black',\n",
    "                weight=1\n",
    "            ).add_to(kart)\n",
    "\n",
    "def legg_til_tegnforklaring(kart, farger):\n",
    "    \"\"\"Legg til tegnforklaring på kartet\"\"\"\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed;\n",
    "                bottom: 50px; right: 50px; width: 150px; height: 160px;\n",
    "                border:2px solid grey; z-index:9999; font-size:12px;\n",
    "                background-color: white; padding: 10px;\n",
    "                border-radius: 5px;\">\n",
    "    <b>Skipstyper:</b><br>\n",
    "    '''\n",
    "\n",
    "    for ship_type, color in farger.items():\n",
    "        legend_html += f'<i class=\"fa fa-ship\" style=\"color:{color}\"></i> Type {ship_type}<br>'\n",
    "\n",
    "    legend_html += '</div>'\n",
    "    kart.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "def hent_tidspunkt_fra_mappe(mappe_navn):\n",
    "    \"\"\"Hent time og minutt fra mappenavnet\"\"\"\n",
    "    match = re.search(r\"time_minutt=(\\d{2})_(\\d{2})\", mappe_navn)\n",
    "    if match:\n",
    "        time, minutt = match.groups()\n",
    "        return time, minutt\n",
    "    return None, None\n",
    "\n",
    "def simuler_datastrømming(hovedmappe, pause_sekunder=0.5, lagre_kart=False):\n",
    "    \"\"\"Simuler datastrømming med visualisering av skipsbevegelser\"\"\"\n",
    "    # Finn alle intervaller\n",
    "    alle_intervaller = finn_minutt_intervaller(hovedmappe)\n",
    "\n",
    "    print(\"\\nSimulerer datastrømming med visualisering...\")\n",
    "    for intervall_dir in alle_intervaller:\n",
    "        # Hent time og minutt fra mappenavnet\n",
    "        time, minutt = hent_tidspunkt_fra_mappe(intervall_dir)\n",
    "        if not time or not minutt:\n",
    "            continue\n",
    "\n",
    "        tidspunkt = f\"{time}:{minutt}\"\n",
    "        intervall_sti = os.path.join(hovedmappe, intervall_dir)\n",
    "\n",
    "        # Vis prosesseringsinformasjon\n",
    "        clear_output(wait=True)  # Fjern forrige output i notebook\n",
    "        print(f\"\\nProsesserer data for {tidspunkt}...\")\n",
    "\n",
    "        # Les data for dette intervallet\n",
    "        samlet_data, antall_filer = les_data_for_intervall(intervall_sti)\n",
    "\n",
    "        if samlet_data is not None:\n",
    "            # Beregn statistikk\n",
    "            stats = beregn_statistikk(samlet_data)\n",
    "\n",
    "            # Vis statistikker\n",
    "            print(f\"Kl. {tidspunkt}: Lastet {stats['totalt_antall_rader']} rader fra {antall_filer} filer\")\n",
    "            print(f\"  Gjennomsnittlig hastighet (SOG): {stats['gjennomsnittlig_hastighet']:.2f}\")\n",
    "            print(f\"  Antall unike skip: {stats['antall_unike_skip']}\")\n",
    "\n",
    "            # Opprett og vis kart\n",
    "            kart = vis_skip_på_kart(samlet_data, f\"Kl. {tidspunkt}\")\n",
    "\n",
    "            # Lagre kartet til en HTML-fil hvis ønsket\n",
    "            if lagre_kart:\n",
    "                kart_filnavn = f\"kart_{time}_{minutt}.html\"\n",
    "                kart.save(kart_filnavn)\n",
    "                print(f\"  Kart lagret som {kart_filnavn}\")\n",
    "\n",
    "            # Vis kartet i notebook\n",
    "            display(kart)\n",
    "        else:\n",
    "            print(f\"Ingen data funnet for kl. {tidspunkt}\")\n",
    "\n",
    "        # Simuler tid mellom intervaller\n",
    "        time_module.sleep(pause_sekunder)\n",
    "\n",
    "    print(\"\\nDatastrømming komplett!\")"
   ],
   "id": "31d5cb94bdf75688"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Simulering og visualisering",
   "id": "8a9f20e9e2023868"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Eksempelbruk i notebook\n",
    "# Sett inn en celle med følgende for å kjøre simuleringen:\n",
    "# simuler_datastrømming(PARTISJON_MAPPE_MIN, pause_sekunder=0.5, lagre_kart=False)"
   ],
   "id": "8a950ae786fc6e77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
