{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2deab54901e5338",
   "metadata": {},
   "source": [
    "# GeoParquet Konverteringsverktøy\n",
    "\n",
    "Dette verktøyet konverterer geografiske datafiler til GeoParquet-format.\n",
    "\n",
    "## Hvordan bruke dette verktøyet\n",
    "\n",
    "1. Last opp dine geografiske datafiler til mappen `data/raw`\n",
    "2. Kjør alle cellene i denne notebooken\n",
    "3. De konverterte filene vil bli lagret i mappen `data/processed`\n",
    "\n",
    "## Støttede filformater\n",
    "\n",
    "- Parquet-filer med geografisk informasjon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60986d44329b74d",
   "metadata": {},
   "source": [
    "## Last inn nødvendige pakker\n",
    "\n",
    "Kjør cellen nedenfor for å importere pakkene som verktøyet trenger:"
   ]
  },
  {
   "cell_type": "code",
   "id": "38a8ca5aadd171dc",
   "metadata": {},
   "source": "!pip install -r requirements.txt",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60001603d8509d85",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkb\n",
    "import time\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87254fc7009f305f",
   "metadata": {},
   "source": [
    "## Definer funksjoner\n",
    "Kjør cellen nedenfor for å definere funksjonene som konverterer filene:"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd4f75424583938d",
   "metadata": {},
   "source": [
    "def opprett_mappestruktur(data_mappe=\"./data\"):\n",
    "    \"\"\"\n",
    "    Oppretter nødvendig mappestruktur for konvertering.\n",
    "\n",
    "    Args:\n",
    "        data_mappe: Sti til hovedmappen for data\n",
    "\n",
    "    Returns:\n",
    "        dict: Stier til opprettede mapper\n",
    "    \"\"\"\n",
    "    # Definer mappestruktur\n",
    "    rå_mappe = os.path.join(data_mappe, \"raw\")\n",
    "    prosessert_mappe = os.path.join(data_mappe, \"processed\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(data_mappe, exist_ok=True)\n",
    "    os.makedirs(rå_mappe, exist_ok=True)\n",
    "    os.makedirs(prosessert_mappe, exist_ok=True)\n",
    "\n",
    "    print(f\"Mappestruktur opprettet.\")\n",
    "\n",
    "    # Returner stier for senere bruk\n",
    "    return {\n",
    "        \"data_mappe\": os.path.abspath(data_mappe),\n",
    "        \"rå_mappe\": os.path.abspath(rå_mappe),\n",
    "        \"prosessert_mappe\": os.path.abspath(prosessert_mappe)\n",
    "    }\n",
    "\n",
    "def legg_til_tidspartisjoneringskolonner(df, tid_kolonne='date_time_utc'):\n",
    "    \"\"\"\n",
    "    Legger til kolonner for tidspartisjonering (år, måned, dag, time).\n",
    "    \"\"\"\n",
    "    if tid_kolonne not in df.columns:\n",
    "        print(f\"Advarsel: Tidsstempelkolonne '{tid_kolonne}' finnes ikke\")\n",
    "        return df\n",
    "\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[tid_kolonne]):\n",
    "        print(f\"Advarsel: Kolonnen '{tid_kolonne}' er ikke en datetime-kolonne\")\n",
    "        return df\n",
    "\n",
    "    df_med_tid = df.copy()\n",
    "    df_med_tid['year'] = df_med_tid[tid_kolonne].dt.year\n",
    "    df_med_tid['month'] = df_med_tid[tid_kolonne].dt.month\n",
    "    df_med_tid['day'] = df_med_tid[tid_kolonne].dt.day\n",
    "    # df_med_tid['hour'] = df_med_tid[tid_kolonne].dt.hour\n",
    "\n",
    "    return df_med_tid\n",
    "\n",
    "def opprett_geodataframe(df):\n",
    "    \"\"\"\n",
    "    Oppretter en GeoDataFrame fra en DataFrame ved å finne koordinater eller geometrikolonner.\n",
    "    \"\"\"\n",
    "    from shapely import wkt\n",
    "    # Sjekk for lat/long kolonner\n",
    "    if 'longitude' in df.columns and 'latitude' in df.columns:\n",
    "        try:\n",
    "            return gpd.GeoDataFrame(\n",
    "                df,\n",
    "                geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "                crs=\"EPSG:4326\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Kunne ikke opprette geometri fra lat/long: {e}\")\n",
    "\n",
    "    # Sjekk for andre geometrikolonner\n",
    "    geom_kolonner = [col for col in df.columns if any(\n",
    "        term in col.lower() for term in ['geom', 'coord', 'point', 'polygon', 'linestring', 'wkt']\n",
    "    )]\n",
    "\n",
    "    for col in geom_kolonner:\n",
    "        if df[col].dtype != 'object':\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            geom = df[col].apply(wkt.loads)\n",
    "            return gpd.GeoDataFrame(df, geometry=geom, crs=\"EPSG:4326\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "\n",
    "def lagre_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner):\n",
    "    \"\"\"\n",
    "    Lagrer en GeoDataFrame som partisjonert GeoParquet.\n",
    "    \"\"\"\n",
    "    from shapely import wkb # NB!! Ikke fjern!\n",
    "\n",
    "    # Konverterer geometri til WKB for å kunne partisjonere\n",
    "    df_med_wkb = gdf.copy()\n",
    "    df_med_wkb['geometry_wkb'] = df_med_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    df_for_partisjon = df_med_wkb.drop(columns=['geometry'])\n",
    "\n",
    "    # Utfør partisjonering\n",
    "    df_for_partisjon.to_parquet(målfilsti, partition_cols=partisjon_kolonner)\n",
    "\n",
    "    # Konverter hver partisjonert fil tilbake til GeoParquet\n",
    "    konverter_partisjonerte_filer_til_geoparquet(målfilsti)\n",
    "    return målfilsti\n",
    "\n",
    "def opprett_år_mappe(år, målfilsti):\n",
    "    \"\"\"Oppretter en mappe for et spesifikt år.\"\"\"\n",
    "    år_mappe = os.path.join(målfilsti, f\"year={år}\")\n",
    "    os.makedirs(år_mappe, exist_ok=True)\n",
    "    return år_mappe\n",
    "\n",
    "def forbered_wkb_dataframe(år_df):\n",
    "    \"\"\"Forbereder en dataframe med WKB-konvertert geometri for partisjonering.\"\"\"\n",
    "    # Konverter geometri til WKB for å kunne partisjonere\n",
    "    år_df_wkb = år_df.copy()\n",
    "    år_df_wkb['geometry_wkb'] = år_df_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    år_df_wkb = år_df_wkb.drop(columns=['geometry'])\n",
    "    return år_df_wkb\n",
    "\n",
    "def konverter_fil_til_geoparquet(src_file, dst_file):\n",
    "    \"\"\"Konverterer en enkelt fil fra WKB-format til GeoParquet.\"\"\"\n",
    "    try:\n",
    "        part_df = pd.read_parquet(src_file)\n",
    "        if 'geometry_wkb' not in part_df.columns:\n",
    "            return False\n",
    "\n",
    "        part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "        part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "        part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "        # Sørg for at målmappen eksisterer\n",
    "        os.makedirs(os.path.dirname(dst_file), exist_ok=True)\n",
    "        part_gdf.to_parquet(dst_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Advarsel: Kunne ikke konvertere {src_file} til GeoParquet: {e}\")\n",
    "        return False\n",
    "\n",
    "def kopier_og_konverter_filer(temp_år_mappe, år_mappe):\n",
    "    \"\"\"Kopierer og konverterer filer fra temp-mappen til målmappen.\"\"\"\n",
    "    suksess_count = 0\n",
    "    feil_count = 0\n",
    "\n",
    "    # Opprett først alle mappene\n",
    "    for root, dirs, _ in os.walk(temp_år_mappe):\n",
    "        for directory in dirs:\n",
    "            src_dir = os.path.join(root, directory)\n",
    "            rel_path = os.path.relpath(src_dir, temp_år_mappe)\n",
    "            dst_dir = os.path.join(år_mappe, rel_path)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # Kopier og konverter filene\n",
    "    for root, _, files in os.walk(temp_år_mappe):\n",
    "        for file in files:\n",
    "            src_file = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(src_file, temp_år_mappe)\n",
    "            dst_file = os.path.join(år_mappe, rel_path)\n",
    "\n",
    "            if konverter_fil_til_geoparquet(src_file, dst_file):\n",
    "                suksess_count += 1\n",
    "            else:\n",
    "                feil_count += 1\n",
    "\n",
    "    return suksess_count, feil_count\n",
    "\n",
    "def lagre_hierarkisk_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner):\n",
    "    \"\"\"\n",
    "    Lagrer en GeoDataFrame med hierarkisk partisjonering der år kommer først,\n",
    "    med saniterte verdier for mappenavn.\n",
    "\n",
    "    Args:\n",
    "        gdf: GeoDataFrame som skal lagres\n",
    "        målfilsti: Base målsti\n",
    "        partisjon_kolonner: Liste av kolonner for partisjonering etter år\n",
    "\n",
    "    Returns:\n",
    "        str: Målfilsti hvis vellykket\n",
    "    \"\"\"\n",
    "    # Legg til sanitiseringsfunksjon\n",
    "    def sanitize_for_partition(value):\n",
    "        \"\"\"Saniterer verdier for bruk i mappenavn\"\"\"\n",
    "        if value is None:\n",
    "            return \"null\"\n",
    "\n",
    "        if isinstance(value, str):\n",
    "            # Erstatt mellomrom og spesialtegn med underscore\n",
    "            sanitized = value.replace(\" \", \"_\")\n",
    "            sanitized = sanitized.replace(\"/\", \"_\")\n",
    "            sanitized = sanitized.replace(\"\\\\\", \"_\")\n",
    "            sanitized = sanitized.replace(\"%\", \"_\")\n",
    "            sanitized = sanitized.replace(\":\", \"_\")\n",
    "            return sanitized\n",
    "\n",
    "        return str(value)\n",
    "\n",
    "    # Sjekk om year er en av kolonnene\n",
    "    if 'year' not in gdf.columns:\n",
    "        print(\"Advarsel: 'year' kolonne finnes ikke for hierarkisk partisjonering\")\n",
    "        return lagre_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner)\n",
    "\n",
    "    # Opprett en temporær mappe for midlertidig lagring\n",
    "    import tempfile\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    try:\n",
    "        # Lag en kopi av dataframen for å sanitere verdier direkte\n",
    "        gdf_kopi = gdf.copy()\n",
    "\n",
    "        # Sanitér verdiene direkte i kolonnene (utenom 'year')\n",
    "        kolonner_å_sanitere = [col for col in partisjon_kolonner if col != 'year']\n",
    "\n",
    "        for kolonne in kolonner_å_sanitere:\n",
    "            if kolonne in gdf_kopi.columns:\n",
    "                # Sanitér verdiene direkte i kolonnen\n",
    "                gdf_kopi[kolonne] = gdf_kopi[kolonne].apply(sanitize_for_partition)\n",
    "\n",
    "        # Partisjonér på år\n",
    "        år_grupper = gdf_kopi.groupby('year')\n",
    "\n",
    "        total_suksess = 0\n",
    "        total_feil = 0\n",
    "\n",
    "        # Filtrer ut year fra partisjoneringskolonnene\n",
    "        andre_kolonner = [col for col in partisjon_kolonner if col != 'year']\n",
    "\n",
    "        # Behandle hvert år\n",
    "        for år, år_df in år_grupper:\n",
    "            år_mappe = opprett_år_mappe(år, målfilsti)\n",
    "\n",
    "            # Hvis det er andre partisjoneringskolonner, partisjonér videre\n",
    "            if andre_kolonner:\n",
    "                # Forbered dataframe for partisjonering\n",
    "                år_df_wkb = forbered_wkb_dataframe(år_df)\n",
    "\n",
    "                # Lag temp-mappe for dette året\n",
    "                temp_år_mappe = os.path.join(temp_dir, f\"year={år}\")\n",
    "                os.makedirs(temp_år_mappe, exist_ok=True)\n",
    "\n",
    "                # Partisjonér data til temp-mappen med saniterte verdier\n",
    "                år_df_wkb.to_parquet(temp_år_mappe, partition_cols=andre_kolonner)\n",
    "\n",
    "                # Kopier og konverter filer til endelig plassering\n",
    "                suksess, feil = kopier_og_konverter_filer(temp_år_mappe, år_mappe)\n",
    "                total_suksess += suksess\n",
    "                total_feil += feil\n",
    "            else:\n",
    "                # Hvis ingen andre partisjoneringskolonner, lagre direkte\n",
    "                år_df.to_parquet(os.path.join(år_mappe, \"data.parquet\"))\n",
    "                total_suksess += 1\n",
    "\n",
    "        if total_feil > 0:\n",
    "            print(f\"Info: {total_suksess} filer konvertert, {total_feil} filer med feil\")\n",
    "\n",
    "        print(f\"Partisjonert med saniterte verdier for kolonnene: {kolonner_å_sanitere}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Feil under hierarkisk partisjonering: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Rydd opp temp-mappen\n",
    "        import shutil\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "    return målfilsti\n",
    "\n",
    "def konverter_partisjonerte_filer_til_geoparquet(rotmappe):\n",
    "    \"\"\"\n",
    "    Konverterer alle partisjonerte parquet-filer til GeoParquet format.\n",
    "    \"\"\"\n",
    "    from shapely import wkb # NB!! Ikke fjern!\n",
    "    feil_count = 0\n",
    "\n",
    "    for root, _, files in os.walk(rotmappe):\n",
    "        for file in files:\n",
    "            if not file.endswith('.parquet'):\n",
    "                continue\n",
    "\n",
    "            parquet_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Les dataframe\n",
    "                part_df = pd.read_parquet(parquet_path)\n",
    "\n",
    "                # Hopp over hvis den ikke har geometry_wkb\n",
    "                if 'geometry_wkb' not in part_df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Konverter WKB tilbake til geometri\n",
    "                part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "                part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "\n",
    "                # Lag GeoDataFrame\n",
    "                part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "                # Skriv GeoParquet-filen\n",
    "                part_gdf.to_parquet(parquet_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Feil ved konvertering av {parquet_path}: {e}\")\n",
    "                feil_count += 1\n",
    "\n",
    "    if feil_count > 0:\n",
    "        print(f\"Advarsel: {feil_count} filer kunne ikke konverteres til GeoParquet\")\n",
    "\n",
    "def konverter_parquet_til_geoparquet(filsti, målfilsti, partisjon_kolonner=None, hierarkisk_år=True):\n",
    "    \"\"\"\n",
    "    Konverterer parquet-fil til GeoParquet-format med partisjonering.\n",
    "\n",
    "    Args:\n",
    "        filsti: Sti til parquet-filen\n",
    "        målfilsti: Sti hvor GeoParquet-filen skal lagres\n",
    "        partisjon_kolonner: Liste av kolonnenavn som skal brukes for partisjonering\n",
    "        hierarkisk_år: Hvis True, partisjoneres hierarkisk med år først\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(filsti)\n",
    "    except Exception as e:\n",
    "        print(f\"Kunne ikke lese parquet-fil: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Håndter tidspartisjonering\n",
    "    tidspartisjonering = False\n",
    "    if partisjon_kolonner and 'date_time_utc' in partisjon_kolonner:\n",
    "        partisjon_kolonner.remove('date_time_utc')\n",
    "        tidspartisjonering = True\n",
    "\n",
    "    # Legg til tidspartisjoneringskolonner\n",
    "    if tidspartisjonering:\n",
    "        df = legg_til_tidspartisjoneringskolonner(df)\n",
    "        if hierarkisk_år:\n",
    "            # For hierarkisk partisjonering, year håndteres separat\n",
    "            # Legg til andre tidskolonner til partisjoneringskolonnene\n",
    "            tidskolonner = ['month', 'day']\n",
    "            partisjon_kolonner = tidskolonner + (partisjon_kolonner or [])\n",
    "        else:\n",
    "            # Standard flat partisjonering\n",
    "            partisjon_kolonner = ['year', 'month', 'day'] + (partisjon_kolonner or [])\n",
    "\n",
    "    # Opprett GeoDataFrame\n",
    "    gdf = opprett_geodataframe(df)\n",
    "    if gdf is None:\n",
    "        return False\n",
    "\n",
    "    # Sjekk at alle partisjoneringskolonner finnes\n",
    "    if partisjon_kolonner and not all(col in gdf.columns for col in partisjon_kolonner):\n",
    "        print(f\"Advarsel: Ikke alle partisjoneringskolonner finnes i datasettet\")\n",
    "        manglende = [col for col in partisjon_kolonner if col not in gdf.columns]\n",
    "        print(f\"Manglende kolonner: {manglende}\")\n",
    "        return False\n",
    "\n",
    "    # Lagre med eller uten partisjonering\n",
    "    if partisjon_kolonner:\n",
    "        if hierarkisk_år and tidspartisjonering:\n",
    "            return lagre_hierarkisk_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner)\n",
    "        else:\n",
    "            return lagre_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner)\n",
    "    else:\n",
    "        gdf.to_parquet(målfilsti)\n",
    "        return målfilsti\n",
    "\n",
    "def konverter_alle_parquet_filer(data_mappe, partisjon_kolonner=None, hierarkisk_år=True):\n",
    "    \"\"\"\n",
    "    Konverterer alle parquet-filer i en mappe til GeoParquet.\n",
    "    \"\"\"\n",
    "    rå_mappe = os.path.join(data_mappe, \"raw\")\n",
    "    prosessert_mappe = os.path.join(data_mappe, \"processed\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(rå_mappe, exist_ok=True)\n",
    "    os.makedirs(prosessert_mappe, exist_ok=True)\n",
    "\n",
    "    resultater = {\n",
    "        \"konvertert\": [],\n",
    "        \"feilet\": []\n",
    "    }\n",
    "\n",
    "    # Finn alle parquet-filer\n",
    "    parquet_filer = [f for f in os.listdir(rå_mappe)\n",
    "                     if f.lower().endswith('.parquet') and os.path.isfile(os.path.join(rå_mappe, f))]\n",
    "\n",
    "    if not parquet_filer:\n",
    "        print(\"Ingen parquet-filer funnet i råmappen\")\n",
    "        return resultater\n",
    "\n",
    "    # Konverter hver fil\n",
    "    for filnavn in parquet_filer:\n",
    "        filsti = os.path.join(rå_mappe, filnavn)\n",
    "        base_filnavn = os.path.splitext(filnavn)[0]\n",
    "        målfilsti = os.path.join(prosessert_mappe, f\"{base_filnavn}.parquet\")\n",
    "\n",
    "        # Konverter filen\n",
    "        resultat = konverter_parquet_til_geoparquet(\n",
    "            filsti,\n",
    "            målfilsti,\n",
    "            partisjon_kolonner.copy() if partisjon_kolonner else None,\n",
    "            hierarkisk_år\n",
    "        )\n",
    "\n",
    "        if resultat:\n",
    "            resultater[\"konvertert\"].append(filsti)\n",
    "        else:\n",
    "            resultater[\"feilet\"].append(filsti)\n",
    "            print(f\"Kunne ikke konvertere: {filsti}\")\n",
    "\n",
    "    return resultater\n",
    "\n",
    "def vis_partisjoneringsstruktur(konvertert_sti):\n",
    "    \"\"\"\n",
    "    Viser partisjoneringsstrukturen for en konvertert fil.\n",
    "    \"\"\"\n",
    "\n",
    "    for root, dirs, files in os.walk(konvertert_sti, topdown=True, followlinks=False):\n",
    "        nivå = root.replace(konvertert_sti, \"\").count(os.sep)\n",
    "        innrykk = \"    \" * (nivå + 1)\n",
    "\n",
    "        # Vis mappenavnet\n",
    "        mappe_navn = os.path.basename(root)\n",
    "        if mappe_navn:  # Ikke vis for rot-mappen\n",
    "            print(f\"{innrykk}- {mappe_navn}\")\n",
    "\n",
    "        # Vis antall filer i dypeste mapper\n",
    "        if not dirs and files:\n",
    "            print(f\"{innrykk}  Inneholder {len(files)} filer\")\n",
    "\n",
    "def vis_datasett_info(filsti):\n",
    "    \"\"\"\n",
    "    Viser informasjon om et GeoParquet datasett.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gdf = gpd.read_parquet(filsti)\n",
    "        print(f\"  Datasett størrelse: {len(gdf)} rader, {len(gdf.columns)} kolonner\")\n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(f\"  Kunne ikke lese filen: {e}\")\n",
    "        return None\n",
    "\n",
    "def start_konvertering(data_mappe=\"./data\", partisjon_kolonner=None, hierarkisk_år=True):\n",
    "    \"\"\"\n",
    "    Start konverteringsprosessen fra Parquet til GeoParquet.\n",
    "\n",
    "    Args:\n",
    "        data_mappe: Sti til datamappen\n",
    "        partisjon_kolonner: Liste av kolonner for partisjonering\n",
    "        hierarkisk_år: Hvis True, partisjoneres først på år, så andre kolonner\n",
    "    \"\"\"\n",
    "    start_tid = time.time()\n",
    "    print(f\"Starter konvertering av parquet-filer i {data_mappe} ...\\n\")\n",
    "\n",
    "    # Opprett raw-mappen\n",
    "    rå_mappe = os.path.join(data_mappe, \"raw\")\n",
    "    os.makedirs(rå_mappe, exist_ok=True)\n",
    "\n",
    "    # Utfør konverteringen\n",
    "    resultater = konverter_alle_parquet_filer(data_mappe, partisjon_kolonner, hierarkisk_år)\n",
    "\n",
    "    print(\"Konvertering og partisjonering utført:\")\n",
    "    print(f\"• Total behandlingstid: {time.time() - start_tid:.2f} sekunder\")\n",
    "    print(f\"• Konverterte filer: {len(resultater['konvertert'])}\")\n",
    "\n",
    "    return resultater"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cd97a5b909f43e0b",
   "metadata": {},
   "source": [
    "## Opprett mappestruktur\n",
    "\n",
    "Kjør cellen nedenfor for å opprette nødvendige mapper:"
   ]
  },
  {
   "cell_type": "code",
   "id": "654efa3b68219f48",
   "metadata": {},
   "source": "mappestier = opprett_mappestruktur()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e8704e106b80a2",
   "metadata": {},
   "source": [
    "## Start konvertering og partisjonering\n",
    "\n",
    "Nå er alt klart! Kjør cellen nedenfor for å starte konvertering og partisjonering:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9f43770e338f323",
   "metadata": {},
   "source": [
    "# Kun konvertering\n",
    "# resultater = start_konvertering(data_mappe=\"./data\")\n",
    "\n",
    "# Manuell konvertering og partisjonering\n",
    "resultater = start_konvertering(data_mappe=\"./data\", partisjon_kolonner=[\"date_time_utc\", \"ship_type\", \"ship_name\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filtrer data",
   "id": "67a799ff6eea8dec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:25:22.557026Z",
     "start_time": "2025-03-30T18:25:22.545176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filtrer_ais_data(\n",
    "    rot_mappe,\n",
    "    dato=None,          # datetime objekt for dato - påkrevd\n",
    "    filtre=None         # Dict med kolonner og verdier å filtrere på\n",
    "):\n",
    "    \"\"\"\n",
    "    Generell filtreringsfunksjon som kan filtrere på alle kolonner.\n",
    "\n",
    "    Args:\n",
    "        rot_mappe: Mappen hvor dataene er lagret\n",
    "        dato: Dato (datetime) som er påkrevd for å finne riktig datapartisjon\n",
    "        filtre: Dict der nøklene er kolonnenavn og verdiene er filterverdier\n",
    "                F.eks. {'ship_name': 'AIDANOVA', 'mmsi': [257376700, 257376701]}\n",
    "    Returns:\n",
    "        GeoDataFrame med filtrerte data\n",
    "    \"\"\"\n",
    "    # Sanitiseringsfunksjon for mappenavn\n",
    "    def sanitize_for_partition(value):\n",
    "        if value is None:\n",
    "            return \"null\"\n",
    "        if isinstance(value, str):\n",
    "            sanitized = value.replace(\" \", \"_\")\n",
    "            sanitized = sanitized.replace(\"/\", \"_\")\n",
    "            sanitized = sanitized.replace(\"\\\\\", \"_\")\n",
    "            sanitized = sanitized.replace(\"%\", \"_\")\n",
    "            sanitized = sanitized.replace(\":\", \"_\")\n",
    "            return sanitized\n",
    "        return str(value)\n",
    "\n",
    "    if not dato:\n",
    "        print(\"Dato er påkrevd\")\n",
    "        return None\n",
    "\n",
    "    if filtre is None:\n",
    "        filtre = {}\n",
    "\n",
    "    # Dato-komponenter er alltid påkrevd for navigering\n",
    "    year, month, day = dato.year, dato.month, dato.day\n",
    "\n",
    "    # Finn basismappe for dato\n",
    "    dato_mapper = [m for m in os.listdir(rot_mappe) if os.path.isdir(os.path.join(rot_mappe, m)) and m.startswith(f\"hais_{dato.strftime('%Y')}\")]\n",
    "\n",
    "    if not dato_mapper:\n",
    "        print(f\"Ingen data funnet for år {year}\")\n",
    "        return None\n",
    "\n",
    "    # Finn alle parquet-filer rekursivt som matcher datokriteriene\n",
    "    data_funnet = []\n",
    "\n",
    "    for dato_mappe in dato_mapper:\n",
    "        base_path = os.path.join(rot_mappe, dato_mappe)\n",
    "\n",
    "        # Traverser mappestrukturen rekursivt\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            # Sjekk om denne mappen inneholder en dato som matcher vår dato\n",
    "            if (f\"year={year}\" in root and\n",
    "                f\"month={month}\" in root and\n",
    "                f\"day={day}\" in root):\n",
    "\n",
    "                # Legg til alle parquet-filer i denne stien\n",
    "                for file in files:\n",
    "                    if file.endswith('.parquet'):\n",
    "                        data_funnet.append(os.path.join(root, file))\n",
    "\n",
    "    if not data_funnet:\n",
    "        print(f\"Ingen parquet-filer funnet for dato {dato.strftime('%Y-%m-%d')}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Fant {len(data_funnet)} parquet-filer for dato {dato.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # Les inn og filtrer dataene\n",
    "    dfs = []\n",
    "    for fil_sti in data_funnet:\n",
    "        try:\n",
    "            # Ekstraher partisjonsverdier fra stien\n",
    "            partitions = {}\n",
    "            parts = fil_sti.split(os.sep)\n",
    "            for part in parts:\n",
    "                if '=' in part:\n",
    "                    key, value = part.split('=', 1)\n",
    "                    partitions[key] = value\n",
    "\n",
    "            # Les parquet-filen\n",
    "            df = pd.read_parquet(fil_sti)\n",
    "\n",
    "            # Legg til partisjonsverdier som kolonner hvis de ikke finnes\n",
    "            for key, value in partitions.items():\n",
    "                df[key] = value\n",
    "\n",
    "            # Filtrer basert på brukerens kriterier\n",
    "            skip_df = False\n",
    "\n",
    "            for kolonne, verdi in filtre.items():\n",
    "                if kolonne not in df.columns:\n",
    "                    skip_df = True\n",
    "                    break\n",
    "\n",
    "                # Sjekk om kolonnen er en partisjonert kolonne\n",
    "                if kolonne in partitions:\n",
    "                    # For partisjonerte kolonner må vi sammenligne med den saniterte verdien\n",
    "                    if isinstance(verdi, list):\n",
    "                        # Hvis vi filtrerer på flere verdier\n",
    "                        sanitized_values = [sanitize_for_partition(v) for v in verdi]\n",
    "                        if partitions[kolonne] not in sanitized_values:\n",
    "                            skip_df = True\n",
    "                            break\n",
    "                    else:\n",
    "                        # Hvis vi filtrerer på én verdi\n",
    "                        sanitized_value = sanitize_for_partition(verdi)\n",
    "                        if partitions[kolonne] != sanitized_value:\n",
    "                            skip_df = True\n",
    "                            break\n",
    "                else:\n",
    "                    # For ikke-partisjonerte kolonner, filtrer på vanlig måte\n",
    "                    if isinstance(verdi, list):\n",
    "                        if not df[kolonne].isin(verdi).any():\n",
    "                            skip_df = True\n",
    "                            break\n",
    "                    else:\n",
    "                        if not (df[kolonne] == verdi).any():\n",
    "                            skip_df = True\n",
    "                            break\n",
    "\n",
    "            if not skip_df:\n",
    "                # Gjør ytterligere filtrering på dataframe-nivå\n",
    "                for kolonne, verdi in filtre.items():\n",
    "                    if kolonne in df.columns and kolonne not in partitions:\n",
    "                        if isinstance(verdi, list):\n",
    "                            df = df[df[kolonne].isin(verdi)]\n",
    "                        else:\n",
    "                            df = df[df[kolonne] == verdi]\n",
    "\n",
    "                if not df.empty:\n",
    "                    dfs.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Feil ved lesing av {fil_sti}: {str(e)}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"Ingen data gjensto etter filtrering\")\n",
    "        return None\n",
    "\n",
    "    # Slå sammen alle dataframes\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Resultatet har {len(combined_df)} rader fra {len(dfs)} filer\")\n",
    "\n",
    "    return combined_df"
   ],
   "id": "4bb341198ef1555e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bruk",
   "id": "72b8c57853f84c2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:39:54.564173Z",
     "start_time": "2025-03-30T18:39:54.440801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resultat = filtrer_ais_data(\n",
    "    rot_mappe=\"data/processed\",\n",
    "    dato=datetime(2024, 5, 3),\n",
    "    filtre={\n",
    "        'ship_name': \"MB HOLLEN\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sjekk resultatet\n",
    "if resultat is not None:\n",
    "    print(\"\\nTilgjengelige kolonner i resultatet:\")\n",
    "    #print(data.columns.tolist())\n",
    "\n",
    "    # Prøv å vise noen kolonner som sannsynligvis finnes\n",
    "    try:\n",
    "        relevante_kolonner = []\n",
    "        for kolonne in ['mmsi', 'ship_name', 'date_time_utc', 'longitude', 'latitude']:\n",
    "            if kolonne in resultat.columns:\n",
    "                relevante_kolonner.append(kolonne)\n",
    "\n",
    "        if relevante_kolonner:\n",
    "            print(f\"\\nFørste 5 rader med utvalgte kolonner:\")\n",
    "            print(resultat[relevante_kolonner].head())\n",
    "        else:\n",
    "            print(\"\\nFørste 5 rader med alle kolonner:\\n\")\n",
    "            print(resultat.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Feil ved visning av data: {str(e)}\")\n",
    "        print(\"Viser alle kolonner i stedet:\")\n",
    "        print(resultat.head())"
   ],
   "id": "28cb8d94b18d537f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fant 26 parquet-filer for dato 2024-05-03\n",
      "Resultatet har 487 rader fra 1 filer\n",
      "\n",
      "Tilgjengelige kolonner i resultatet:\n",
      "\n",
      "Første 5 rader med utvalgte kolonner:\n",
      "        mmsi  ship_name       date_time_utc  longitude  latitude\n",
      "0  257120700  MB_HOLLEN 2024-05-03 05:07:45   7.988333     58.11\n",
      "1  257120700  MB_HOLLEN 2024-05-03 06:25:44   7.988333     58.11\n",
      "2  257120700  MB_HOLLEN 2024-05-03 06:28:44   7.988333     58.11\n",
      "3  257120700  MB_HOLLEN 2024-05-03 06:31:44   7.988333     58.11\n",
      "4  257120700  MB_HOLLEN 2024-05-03 10:31:44   7.988333     58.11\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cfab58e2e8b2226c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
