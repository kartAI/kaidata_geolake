{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ac5365916b1779c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Parquet konvertering-, partisjonering- og filtreringsverktøy for AIS-data\n",
    "\n",
    "Dette verktøyet konverterer Parquet-filer til GeoParquet-format, partisjonerer på angitte kolonner og filtrerer på angitt dato og radius rundt Kristiansand sentrum. Data vises på tabell og kart.\n",
    "\n",
    "Verktøyet er en løsningsmodell som bruker GeoPandas for følgende brukerhistorie:\n",
    "\n",
    "\"Som havnesjef i Kristiansand kommune ønsker jeg å vite hvilke skip som befant seg innen 6 km fra Kristiansand sentrum på en bestemt dato.\"\n",
    "\n",
    "### Hvordan bruke dette verktøyet\n",
    "1. Last opp dine geografiske datafiler til mappen `data/raw`\n",
    "2. Kjør alle cellene i denne notebooken\n",
    "3. De konverterte filene vil bli lagret i mappen `data/processed`\n",
    "\n",
    "### Støttede filformater\n",
    "\n",
    "- Parquet-filer med geografisk informasjon"
   ],
   "id": "63e7c37215e5785b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Last inn nødvendige pakker\n",
    "\n",
    "Kjør cellen nedenfor for å installere og importere pakkene som verktøyet trenger:"
   ],
   "id": "2d76f38be6887fa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -r requirements.txt",
   "id": "2e9dd0461016655"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "from shapely import wkb\n",
    "from shapely.geometry import Point, Polygon\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n"
   ],
   "id": "76d14711922791d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Globale variabler",
   "id": "483fd680ce71a80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_current_observer = None\n",
    "global_paths = None\n",
    "\n",
    "# Sett standardverdier for parameterne\n",
    "data_dir = \"./data\""
   ],
   "id": "fa0a2754f7d25edf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Definer funksjoner\n",
    "Kjør cellen nedenfor for å definere nødvendige funksjoner:"
   ],
   "id": "3eaff8db5d849848"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---------- MAPPESTRUKTUR ---------- #\n",
    "\n",
    "def create_folders(data_folder=\"./data\"):\n",
    "    \"\"\"\n",
    "    Oppretter nødvendig mappestruktur for konvertering.\n",
    "\n",
    "    Args:\n",
    "        data_folder: Sti til hovedmappen for data\n",
    "\n",
    "    Returns:\n",
    "        dict: Stier til opprettede mapper\n",
    "    \"\"\"\n",
    "    # Definer mappestruktur\n",
    "    raw_folder = os.path.join(data_folder, \"raw\")\n",
    "    processed_folder = os.path.join(data_folder, \"processed\")\n",
    "    source_folder = os.path.join(data_folder, \"source\")\n",
    "    incoming_folder = os.path.join(data_folder, \"incoming\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    os.makedirs(raw_folder, exist_ok=True)\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "    os.makedirs(source_folder, exist_ok=True)\n",
    "    os.makedirs(incoming_folder, exist_ok=True)\n",
    "\n",
    "    # Returner stier for senere bruk\n",
    "    return {\n",
    "        \"raw_folder\": os.path.abspath(data_folder),\n",
    "        \"processed_folder\": os.path.abspath(raw_folder),\n",
    "        \"prosessert_mappe\": os.path.abspath(processed_folder),\n",
    "        \"source_folder\": os.path.abspath(source_folder),\n",
    "        \"incoming_folder\": os.path.abspath(incoming_folder)\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- KONVERTERING & PARTISJONERING ---------- #\n",
    "\n",
    "def add_time_partitioning_columns(df, time_column='date_time_utc'):\n",
    "    \"\"\"\n",
    "    Legger til kolonner for tidspartisjonering (kun time for partisjonering, men beholder dato-kolonner).\n",
    "    \"\"\"\n",
    "    if time_column not in df.columns:\n",
    "        print(f\"Advarsel: Tidsstempelkolonne '{time_column}' finnes ikke\")\n",
    "        return df\n",
    "\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[time_column]):\n",
    "        print(f\"Advarsel: Kolonnen '{time_column}' er ikke en datetime-kolonne\")\n",
    "        return df\n",
    "\n",
    "    df_with_time = df.copy()\n",
    "    df_with_time['year'] = df_with_time[time_column].dt.year\n",
    "    df_with_time['month'] = df_with_time[time_column].dt.month\n",
    "    df_with_time['day'] = df_with_time[time_column].dt.day\n",
    "    df_with_time['hour'] = df_with_time[time_column].dt.hour\n",
    "\n",
    "    return df_with_time\n",
    "\n",
    "def create_geodataframe(df):\n",
    "    \"\"\"\n",
    "    Oppretter en GeoDataFrame fra en DataFrame ved å finne koordinater eller geometrikolonner.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sjekk for lat/long kolonner\n",
    "    if 'longitude' in df.columns and 'latitude' in df.columns:\n",
    "        try:\n",
    "            return gpd.GeoDataFrame(\n",
    "                df,\n",
    "                geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "                crs=\"EPSG:4326\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Kunne ikke opprette geometri fra lat/long: {e}\")\n",
    "\n",
    "    # Sjekk for andre geometrikolonner\n",
    "    geom_columns = [col for col in df.columns if any(\n",
    "        term in col.lower() for term in ['geom', 'coord', 'point', 'polygon', 'linestring', 'wkt']\n",
    "    )]\n",
    "\n",
    "    for col in geom_columns:\n",
    "        if df[col].dtype != 'object':\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            geom = df[col].apply(wkt.loads)\n",
    "            return gpd.GeoDataFrame(df, geometry=geom, crs=\"EPSG:4326\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_partitioned_geoparquet(gdf, output_path, partition_columns):\n",
    "    \"\"\"\n",
    "    Lagrer en GeoDataFrame som partisjonert GeoParquet.\n",
    "    \"\"\"\n",
    "\n",
    "    # Konverterer geometri til WKB for å kunne partisjonere\n",
    "    df_med_wkb = gdf.copy()\n",
    "    df_med_wkb['geometry_wkb'] = df_med_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    df_for_partisjon = df_med_wkb.drop(columns=['geometry'])\n",
    "\n",
    "    # Utfør partisjonering\n",
    "    df_for_partisjon.to_parquet(output_path, partition_cols=partition_columns)\n",
    "\n",
    "    # Konverter hver partisjonert fil tilbake til GeoParquet\n",
    "    convert_partitioned_files_to_geoparquet(output_path)\n",
    "    return output_path\n",
    "\n",
    "def create_year_folder(year, output_path):\n",
    "    \"\"\"Oppretter en mappe for et spesifikt år.\"\"\"\n",
    "    year_folder = os.path.join(output_path, f\"year={year}\")\n",
    "    os.makedirs(year_folder, exist_ok=True)\n",
    "    return year_folder\n",
    "\n",
    "def prepare_wkb_dataframe(year_df):\n",
    "    \"\"\"Forbereder en dataframe med WKB-konvertert geometri for partisjonering.\"\"\"\n",
    "    # Konverter geometri til WKB for å kunne partisjonere\n",
    "    year_df_wkb = year_df.copy()\n",
    "    year_df_wkb['geometry_wkb'] = year_df_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    year_df_wkb = year_df_wkb.drop(columns=['geometry'])\n",
    "    return year_df_wkb\n",
    "\n",
    "def convert_file_to_geoparquet(src_file, dst_file):\n",
    "    \"\"\"Konverterer en enkelt fil fra WKB-format til GeoParquet.\"\"\"\n",
    "    try:\n",
    "        part_df = pd.read_parquet(src_file)\n",
    "        if 'geometry_wkb' not in part_df.columns:\n",
    "            return False\n",
    "\n",
    "        part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "        part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "        part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "        # Sørg for at målmappen eksisterer\n",
    "        os.makedirs(os.path.dirname(dst_file), exist_ok=True)\n",
    "        part_gdf.to_parquet(dst_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Advarsel: Kunne ikke konvertere {src_file} til GeoParquet: {e}\")\n",
    "        return False\n",
    "\n",
    "def copy_and_convert_files(temp_year_folder, year_folder):\n",
    "    \"\"\"Kopierer og konverterer filer fra temp-mappen til målmappen.\"\"\"\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    # Opprett først alle mappene\n",
    "    for root, dirs, _ in os.walk(temp_year_folder):\n",
    "        for directory in dirs:\n",
    "            src_dir = os.path.join(root, directory)\n",
    "            rel_path = os.path.relpath(src_dir, temp_year_folder)\n",
    "            dst_dir = os.path.join(year_folder, rel_path)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # Kopier og konverter filene\n",
    "    for root, _, files in os.walk(temp_year_folder):\n",
    "        for file in files:\n",
    "            src_file = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(src_file, temp_year_folder)\n",
    "            dst_file = os.path.join(year_folder, rel_path)\n",
    "\n",
    "            if convert_file_to_geoparquet(src_file, dst_file):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "\n",
    "    return success_count, error_count\n",
    "\n",
    "def convert_partitioned_files_to_geoparquet(root_folder):\n",
    "    \"\"\"\n",
    "    Konverterer alle partisjonerte parquet-filer til GeoParquet format.\n",
    "    \"\"\"\n",
    "    error_count = 0\n",
    "\n",
    "    for root, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if not file.endswith('.parquet'):\n",
    "                continue\n",
    "\n",
    "            parquet_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Les dataframe\n",
    "                part_df = pd.read_parquet(parquet_path)\n",
    "\n",
    "                # Hopp over hvis den ikke har geometry_wkb\n",
    "                if 'geometry_wkb' not in part_df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Konverter WKB tilbake til geometri\n",
    "                part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "                part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "\n",
    "                # Lag GeoDataFrame\n",
    "                part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "                # Skriv GeoParquet-filen\n",
    "                part_gdf.to_parquet(parquet_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Feil ved konvertering av {parquet_path}: {e}\")\n",
    "                error_count += 1\n",
    "\n",
    "    if error_count > 0:\n",
    "        print(f\"Advarsel: {error_count} filer kunne ikke konverteres til GeoParquet\")\n",
    "\n",
    "def convert_parquet_to_geoparquet(file_path, output_path, partition_columns=None):\n",
    "    \"\"\"\n",
    "    Konverterer parquet-fil til GeoParquet-format med partisjonering.\n",
    "    Args:\n",
    "        file_path: Sti til parquet-filen\n",
    "        output_path: Sti hvor GeoParquet-filen skal lagres\n",
    "        partition_columns: Liste av kolonnenavn som skal brukes for partisjonering\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Kunne ikke lese parquet-fil: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Håndter tidspartisjonering\n",
    "    time_partitioning = False\n",
    "    if partition_columns and 'date_time_utc' in partition_columns:\n",
    "        partition_columns.remove('date_time_utc')\n",
    "        time_partitioning = True\n",
    "\n",
    "    # Legg til alle tidspartisjoneringskolonner, men vi vil bare partisjonere på time\n",
    "    if time_partitioning:\n",
    "        df = add_time_partitioning_columns(df)\n",
    "        # Sett opp partisjonering kun på 'hour'\n",
    "        partition_columns = ['hour'] + (partition_columns or [])\n",
    "\n",
    "    # Opprett GeoDataFrame\n",
    "    gdf = create_geodataframe(df)\n",
    "    if gdf is None:\n",
    "        return False\n",
    "\n",
    "    # Sjekk at alle partisjoneringskolonner finnes\n",
    "    if partition_columns and not all(col in gdf.columns for col in partition_columns):\n",
    "        print(f\"Advarsel: Ikke alle partisjoneringskolonner finnes i datasettet\")\n",
    "        missing = [col for col in partition_columns if col not in gdf.columns]\n",
    "        print(f\"Manglende kolonner: {missing}\")\n",
    "        return False\n",
    "\n",
    "    # Lagre med partisjonering (bare time)\n",
    "    if partition_columns:\n",
    "        return save_partitioned_geoparquet(gdf, output_path, partition_columns)\n",
    "    else:\n",
    "        gdf.to_parquet(output_path)\n",
    "        return output_path\n",
    "\n",
    "def convert_all_parquet_files(data_folder, partition_columns=None):\n",
    "    \"\"\"\n",
    "    Konverterer alle parquet-filer i en mappe til GeoParquet.\n",
    "    \"\"\"\n",
    "    raw_folder = os.path.join(data_folder, \"raw\")\n",
    "    processed_folder = os.path.join(data_folder, \"processed\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(raw_folder, exist_ok=True)\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    results = {\n",
    "        \"converted\": [],\n",
    "        \"failed\": []\n",
    "    }\n",
    "\n",
    "    # Finn alle parquet-filer\n",
    "    parquet_files = [f for f in os.listdir(raw_folder)\n",
    "                     if f.lower().endswith('.parquet') and os.path.isfile(os.path.join(raw_folder, f))]\n",
    "\n",
    "    if not parquet_files:\n",
    "        print(\"Ingen parquet-filer funnet i råmappen\")\n",
    "        return results\n",
    "\n",
    "    # Konverter hver fil\n",
    "    for filename in parquet_files:\n",
    "        file_path = os.path.join(raw_folder, filename)\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        output_path = os.path.join(processed_folder, f\"{base_filename}.parquet\")\n",
    "\n",
    "        # Konverter filen\n",
    "        resultat = convert_parquet_to_geoparquet(\n",
    "            file_path,\n",
    "            output_path,\n",
    "            partition_columns.copy() if partition_columns else None,\n",
    "        )\n",
    "\n",
    "        if resultat:\n",
    "            results[\"converted\"].append(file_path)\n",
    "        else:\n",
    "            results[\"failed\"].append(file_path)\n",
    "            print(f\"Kunne ikke konvertere: {file_path}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def start_conversion(data_folder=\"./data\", partition_columns=None):\n",
    "    \"\"\"\n",
    "    Start konverteringsprosessen fra Parquet til GeoParquet.\n",
    "    Args:\n",
    "        data_folder: Sti til datamappen\n",
    "        partition_columns: Liste av kolonner for partisjonering\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Starter konvertering og partisjonering av parquet-filer i {data_folder} ...\\n\")\n",
    "    print(f\"Partisjonering vil skje på time og følgende kolonner: {partition_columns or []}\")\n",
    "\n",
    "    # Opprett og sjekk mappene\n",
    "    folder_paths = create_folders(data_folder)\n",
    "    raw_folder = folder_paths[\"raw_folder\"]\n",
    "\n",
    "    # Utfør konverteringen\n",
    "    results = convert_all_parquet_files(data_folder, partition_columns)\n",
    "\n",
    "    print(\"Konvertering og partisjonering utført:\")\n",
    "    print(f\"• Total behandlingstid: {time.time() - start_time:.2f} sekunder\")\n",
    "    print(f\"• Konverterte filer: {len(results['converted'])}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# ---------- FILTRERING ---------- #\n",
    "\n",
    "def define_agder_polygon():\n",
    "    \"\"\"\n",
    "    Definerer et forenklet polygon for Agder-kysten.\n",
    "\n",
    "    Returns:\n",
    "        Shapely Polygon som definerer Agder-kystlinjen\n",
    "    \"\"\"\n",
    "\n",
    "    agder_coords = [\n",
    "        (6.8, 57.8),  # Sørvest\n",
    "        (10.0, 57.8),  # Sørøst\n",
    "        (10.0, 59.5),  # Nordøst\n",
    "        (6.8, 59.5),  # Nordvest\n",
    "        (6.8, 57.8)   # Lukk polygonet\n",
    "    ]\n",
    "    return Polygon(agder_coords)\n",
    "\n",
    "def filter_ais_data(\n",
    "    root_folder,\n",
    "    date=None,  # datetime objekt for dato - påkrevd\n",
    "    filters=None,  # Dict med kolonner og verdier å filtrere på\n",
    "    agder_polygon=None,  # GeoDataFrame eller Shapely polygon for Agder-kysten\n",
    "    max_number_of_ships=10  # Maksimalt antall unike skip å returnere\n",
    "):\n",
    "    \"\"\"\n",
    "    Filtrerer AIS-data basert på dato og geografisk område.\n",
    "\n",
    "    Args:\n",
    "        root_folder: Mappen hvor dataene er lagret\n",
    "        date: Dato for filtrering\n",
    "        filters: Dictionary med kolonnenavn og verdier for filtrering\n",
    "        agder_polygon: Polygon som definerer Agder-kysten\n",
    "        max_number_of_ships: Maksimalt antall skip å returnere\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame med filtrerte skip\n",
    "    \"\"\"\n",
    "    if not date:\n",
    "        print(\"Dato er påkrevd\")\n",
    "        return None\n",
    "\n",
    "    if filters is None:\n",
    "        filters = {}\n",
    "\n",
    "    # Dato-komponenter for filtrering senere\n",
    "    year, month, day = date.year, date.month, date.day\n",
    "\n",
    "    # Konverter dato til string for bruk i filnavn\n",
    "    dato_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # Sjekk om rot-mappen eksisterer\n",
    "    if not os.path.exists(root_folder):\n",
    "        print(f\"Mappen {root_folder} finnes ikke\")\n",
    "        return None\n",
    "\n",
    "    # Finn alle mapper i rot-mappen\n",
    "    date_folders = []\n",
    "    for element in os.listdir(root_folder):\n",
    "        full_path = os.path.join(root_folder, element)\n",
    "        if os.path.isdir(full_path):\n",
    "            date_folders.append(element)\n",
    "\n",
    "    if not date_folders:\n",
    "        print(f\"Ingen datamapper funnet i {root_folder}\")\n",
    "        return None\n",
    "\n",
    "    # Finn alle parquet-filer rekursivt\n",
    "    date_found = []\n",
    "\n",
    "    for date_folder in date_folders:\n",
    "        base_path = os.path.join(root_folder, date_folder)\n",
    "        # Traverser mappestrukturen rekursivt\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            # For time-partisjonering, sjekk fil-innhold istedenfor å basere på katalogstruktur\n",
    "            for file in files:\n",
    "                if file.endswith('.parquet'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    date_found.append(file_path)\n",
    "\n",
    "    if not date_found:\n",
    "        print(f\"Ingen parquet-filer funnet\")\n",
    "        return None\n",
    "\n",
    "    # Les inn og filtrer dataene\n",
    "    dfs = []\n",
    "    for file_path in date_found:\n",
    "        try:\n",
    "            # Ekstraher partisjonsverdier fra stien (for time)\n",
    "            time_value = None\n",
    "            parts = file_path.split(os.sep)\n",
    "            for part in parts:\n",
    "                if part.startswith('hour='):\n",
    "                    time_value = int(part.split('=')[1])\n",
    "\n",
    "            # Les parquet-filen\n",
    "            df = pd.read_parquet(file_path)\n",
    "\n",
    "            # Legg til hour som kolonne hvis den ikke allerede finnes\n",
    "            if time_value is not None and 'hour' not in df.columns:\n",
    "                df['hour'] = time_value\n",
    "\n",
    "            # Filtrer på dato\n",
    "            if 'year' in df.columns and 'month' in df.columns and 'day' in df.columns:\n",
    "                df = df[(df['year'] == year) & (df['month'] == month) & (df['day'] == day)]\n",
    "\n",
    "                if df.empty:\n",
    "                    # Hopp over denne filen hvis ingen rader matcher datoen\n",
    "                    continue\n",
    "\n",
    "            # Utfør ekstra filtrering basert på filtre-parameteren\n",
    "            ship_df = False\n",
    "            for columns, value in filters.items():\n",
    "                if columns not in df.columns:\n",
    "                    ship_df = True\n",
    "                    break\n",
    "\n",
    "                # For alle kolonner, filtrer på vanlig måte\n",
    "                if isinstance(value, list):\n",
    "                    if not df[columns].isin(value).any():\n",
    "                        ship_df = True\n",
    "                        break\n",
    "                else:\n",
    "                    if not (df[columns] == value).any():\n",
    "                        ship_df = True\n",
    "                        break\n",
    "\n",
    "            if not ship_df:\n",
    "                # Gjør ytterligere filtrering på dataframe-nivå\n",
    "                for columns, value in filters.items():\n",
    "                    if columns in df.columns:\n",
    "                        if isinstance(value, list):\n",
    "                            df = df[df[columns].isin(value)]\n",
    "                        else:\n",
    "                            df = df[df[columns] == value]\n",
    "\n",
    "                if not df.empty:\n",
    "                    dfs.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Feil ved lesing av {file_path}: {str(e)}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"Ingen data lest inn\")\n",
    "        return None\n",
    "\n",
    "    # Slå sammen alle dataframes\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Konverter til GeoDataFrame hvis koordinater finnes\n",
    "    if 'longitude' in combined_df.columns and 'latitude' in combined_df.columns:\n",
    "        # Opprett geometrikolonne fra longitude og latitude\n",
    "        geometry = [Point(xy) for xy in zip(combined_df['longitude'], combined_df['latitude'])]\n",
    "        geo_df = gpd.GeoDataFrame(combined_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "        # Filtrer basert på Agder-polygon hvis gitt\n",
    "        if agder_polygon is not None:\n",
    "            # Sjekk om agder_polygon er et GeoDataFrame eller et Shapely-objekt\n",
    "            if isinstance(agder_polygon, gpd.GeoDataFrame):\n",
    "                # Sørg for at CRS er likt\n",
    "                if agder_polygon.crs != geo_df.crs:\n",
    "                    agder_polygon = agder_polygon.to_crs(geo_df.crs)\n",
    "\n",
    "                # Spatial join - dette kan ta litt tid for store datasett\n",
    "                geo_df = gpd.sjoin(geo_df, agder_polygon, how=\"inner\", predicate=\"within\")\n",
    "            else:\n",
    "                # Antar at agder_polygon er et Shapely-objekt\n",
    "                geo_df = geo_df[geo_df.geometry.within(agder_polygon)]\n",
    "\n",
    "        # Sorter etter nyeste data først for hvert skip\n",
    "        if 'timestamp' in geo_df.columns:\n",
    "            geo_df = geo_df.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "        # Begrens til unike skip\n",
    "        if 'mmsi' in geo_df.columns or 'ship_name' in geo_df.columns:\n",
    "            id_columns = 'mmsi' if 'mmsi' in geo_df.columns else 'ship_name'\n",
    "            unique_ships = geo_df[id_columns].unique()\n",
    "\n",
    "            if len(unique_ships) > max_number_of_ships:\n",
    "                print(f\"Begrenser til {max_number_of_ships} skip\")\n",
    "                unique_ships = unique_ships[:max_number_of_ships]\n",
    "\n",
    "            geo_df = geo_df[geo_df[id_columns].isin(unique_ships)]\n",
    "\n",
    "            # Hent første rad for hvert unikt skip for å få en kompakt liste\n",
    "            geo_df = geo_df.drop_duplicates(subset=[id_columns])\n",
    "\n",
    "        return geo_df\n",
    "    else:\n",
    "        print(\"Mangler koordinater (longitude/latitude)\")\n",
    "        return None\n",
    "\n",
    "def find_ships_near_point(ship_gdf, point, buffer_distance=500):\n",
    "    \"\"\"\n",
    "    Filtrerer skip som er innenfor en gitt avstand fra et punkt.\n",
    "\n",
    "    Args:\n",
    "        ship_gdf: GeoDataFrame med skip\n",
    "        point: Tuple (longitude, latitude)\n",
    "        buffer_distance: Avstand i meter\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame med filtrerte skip\n",
    "    \"\"\"\n",
    "    if ship_gdf is None or ship_gdf.empty:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Opprett punkt fra koordinater\n",
    "        center_point = Point(point)\n",
    "\n",
    "        # Projiser til et lokalt koordinatsystem som bruker meter som enheter (UTM-sone)\n",
    "        # Finn UTM-sone basert på longitude\n",
    "        utm_sone = int((point[0] + 180) / 6) + 1\n",
    "        utm_crs = f\"EPSG:326{utm_sone}\"  # Nordlig halvkule\n",
    "\n",
    "        # Transformer funksjonen for å lage buffer i meter\n",
    "        project_to_utm = pyproj.Transformer.from_crs(\n",
    "            \"EPSG:4326\", utm_crs, always_xy=True).transform\n",
    "        project_to_wgs84 = pyproj.Transformer.from_crs(\n",
    "            utm_crs, \"EPSG:4326\", always_xy=True).transform\n",
    "\n",
    "        # Projiser punkt til UTM, lag buffer i meter, projiser tilbake til WGS84\n",
    "        utm_point = transform(project_to_utm, center_point)\n",
    "        buffer_utm = utm_point.buffer(buffer_distance)\n",
    "        buffer_wgs84 = transform(project_to_wgs84, buffer_utm)\n",
    "\n",
    "        # Filtrer for skip innenfor bufferen\n",
    "        ships_within_buffer = ship_gdf[ship_gdf.geometry.within(buffer_wgs84)]\n",
    "        print(f\"Fant {len(ships_within_buffer)} skip innenfor {buffer_distance}m fra punktet\")\n",
    "\n",
    "        return ships_within_buffer, buffer_wgs84\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Feil ved buffering: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def filtrer_skip_agder(root_folder, dato, radius=None, center_point=(8.0182, 58.1599), number_of_ships=10):\n",
    "    \"\"\"\n",
    "    Filtrerer skip i Agder-området, enten basert på et definert polygon eller en radius fra et senterpunkt.\n",
    "\n",
    "    Args:\n",
    "        root_folder: Mappen hvor de konverterte dataene er lagret\n",
    "        dato: Datoen å filtrere på (datetime objekt)\n",
    "        radius: Radius i meter fra senterpunkt (None = bruk polygon)\n",
    "        center_point: Tuple (longitude, latitude) for senterpunkt (standard: Kristiansand)\n",
    "        number_of_ships: Maksimalt antall skip å returnere\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame med filtrerte skip\n",
    "    \"\"\"\n",
    "    # Først hent alle skip for datoen uten geografisk filtrering\n",
    "    ships_on_date = filter_ais_data(\n",
    "        root_folder=root_folder,\n",
    "        date=dato,\n",
    "        filters=None,\n",
    "        agder_polygon=None,  # Ingen geografisk filter her ennå\n",
    "        max_number_of_ships=100  # Hent litt flere for å kunne filtrere geografisk etterpå\n",
    "    )\n",
    "\n",
    "    if ships_on_date is None or ships_on_date.empty:\n",
    "        print(f\"Ingen skip funnet på datoen {dato.strftime('%d.%m.%Y')}\")\n",
    "        return None\n",
    "\n",
    "    # Hvis radius er oppgitt, bruk finn_skip_rundt_punkt\n",
    "    if radius is not None and radius > 0:\n",
    "        print(f\"Søker etter skip innen {radius} meter fra senterpunkt\")\n",
    "        ships_near_point, buffer = find_ships_near_point(\n",
    "            ships_on_date,\n",
    "            center_point,\n",
    "            buffer_distance=radius\n",
    "        )\n",
    "\n",
    "        # Begrens antall skip hvis nødvendig\n",
    "        if ships_near_point is not None and len(ships_near_point) > number_of_ships:\n",
    "            ships_near_point = ships_near_point.head(number_of_ships)\n",
    "\n",
    "        if ships_near_point is None or ships_near_point.empty:\n",
    "            print(f\"Ingen skip funnet innenfor {radius}m fra senterpunkt på datoen {dato.strftime('%d.%m.%Y')}\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Fant {len(ships_near_point)} skip innenfor {radius}m på datoen {dato.strftime('%d.%m.%Y')}\")\n",
    "        return ships_near_point\n",
    "    else:\n",
    "        # Bruk standard Agder-polygon\n",
    "        agder_polygon = define_agder_polygon()\n",
    "\n",
    "        # Filtrer med polygon\n",
    "        ships_within_agder = ships_on_date[ships_on_date.geometry.within(agder_polygon)]\n",
    "\n",
    "        # Begrens antall skip\n",
    "        if len(ships_within_agder) > number_of_ships:\n",
    "            ships_within_agder = ships_within_agder.head(number_of_ships)\n",
    "\n",
    "        if ships_within_agder.empty:\n",
    "            print(f\"Ingen skip funnet innenfor Agder-område på datoen {dato.strftime('%d.%m.%Y')}\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Fant {len(ships_within_agder)} skip innenfor Agder-område på datoen {dato.strftime('%d.%m.%Y')}\")\n",
    "        return ships_within_agder\n"
   ],
   "id": "4372838041ffb7e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyse over skip i Agder",
   "id": "9b6aae36095afa0d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtrer skip i Agder for en bestemt dato\n",
    "root_folder = \"data/processed\"\n",
    "date = datetime.datetime(2024, 5, 16)  # Velg dato\n",
    "ships_in_agder = filtrer_skip_agder(root_folder, date)\n",
    "\n",
    "# Vis skipene på tabellform\n",
    "if ships_in_agder is not None and not ships_in_agder.empty:\n",
    "    # Velg kolonner å vise\n",
    "    columns = ['mmsi', 'ship_name', 'ship_type', 'longitude', 'latitude']\n",
    "\n",
    "    # Velg bare kolonner som faktisk finnes i datasettet\n",
    "    available_columns = [kol for kol in columns if kol in ships_in_agder.columns]\n",
    "\n",
    "    styled_tabell = ships_in_agder[available_columns].style \\\n",
    "        .format({'longitude': '{:.4f}', 'latitude': '{:.4f}'}) \\\n",
    "        .set_caption('Skip innenfor Agder-området') \\\n",
    "        .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#f2f2f2'),\n",
    "                                     ('color', '#333'),\n",
    "                                     ('font-weight', 'bold')]},\n",
    "        {'selector': 'td', 'props': [('padding', '5px')]}\n",
    "    ])\n",
    "\n",
    "    display(styled_tabell)\n",
    "else:\n",
    "    print(\"Ingen skip å vise.\")"
   ],
   "id": "60039066bf35c1d0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
