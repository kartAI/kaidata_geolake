{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704b21668faf5817",
   "metadata": {},
   "source": [
    "## 1. Last inn data:"
   ]
  },
  {
   "cell_type": "code",
   "id": "15c287b004f87bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T20:52:44.135262Z",
     "start_time": "2025-04-26T20:52:44.132716Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from shapely import wkb"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "41459ec876a1de14",
   "metadata": {},
   "source": [
    "## Utfør partisjonering\n",
    "Merk at du må slette `data` mappa om du har kjørt u1_ eller u2_ og opprette ny, samt legge inn filene i `data/raw` på nytt!"
   ]
  },
  {
   "cell_type": "code",
   "id": "93b66f6ce33377a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T20:54:28.082221Z",
     "start_time": "2025-04-26T20:54:28.067084Z"
    }
   },
   "source": [
    "DATA_DIR = \"AIS/Data\"\n",
    "PROCESSED_DIR = \"AIS/Data/processed\"\n",
    "\n",
    "CENTER_POINT_KRS = (8.0182, 58.1599) # (longitude, latitude)\n",
    "STD_BUFFER_DISTANCE = 500 #meter\n",
    "STD_RADIUS = 1000 #meter\n",
    "STD_CRS = 'EPSG:4326'\n",
    "\n",
    "TIME_COLUMN = 'date_time_utc'\n",
    "STD_PARTITION_COLUMNS = ['date_time_utc', 'ship_type']\n",
    "SHIP_DISPLAY_COLUMNS = ['mmsi', 'ship_name', 'ship_type', 'longitude', 'latitude']\n",
    "\n",
    "NUM_OF_SHIPS = 10\n",
    "MAX_NUM_OF_SHIPS = 100\n",
    "\n",
    "def create_folders(DATA_DIR):\n",
    "    \"\"\"\n",
    "    Oppretter nødvendig mappestruktur for konvertering.\n",
    "\n",
    "    Args:\n",
    "        data_folder: Sti til hovedmappen for data\n",
    "\n",
    "    Returns:\n",
    "        dict: Stier til opprettede mapper\n",
    "    \"\"\"\n",
    "    # Definer mappestruktur\n",
    "    raw_folder = os.path.join(DATA_DIR, \"raw\")\n",
    "    processed_folder = os.path.join(DATA_DIR, \"processed\")\n",
    "    source_folder = os.path.join(DATA_DIR, \"source\")\n",
    "    incoming_folder = os.path.join(DATA_DIR, \"incoming\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(raw_folder, exist_ok=True)\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "    os.makedirs(source_folder, exist_ok=True)\n",
    "    os.makedirs(incoming_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Mappestruktur opprettet.\")\n",
    "\n",
    "    # Returner stier for senere bruk\n",
    "    return {\n",
    "        \"data_folder\": os.path.abspath(DATA_DIR),\n",
    "        \"raw_folder\": os.path.abspath(raw_folder),\n",
    "        \"processed_folder\": os.path.abspath(processed_folder),\n",
    "        \"source_folder\": os.path.abspath(source_folder),\n",
    "        \"incoming_folder\": os.path.abspath(incoming_folder)\n",
    "    }\n",
    "\n",
    "def add_time_partitioning_columns(df, time_column=TIME_COLUMN):\n",
    "    \"\"\"\n",
    "    Legger til kolonner for tidspartisjonering (kun time for partisjonering, men beholder dato-kolonner).\n",
    "    \"\"\"\n",
    "    if time_column not in df.columns:\n",
    "        print(f\"Advarsel: Tidsstempelkolonne '{time_column}' finnes ikke\")\n",
    "        return df\n",
    "\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[time_column]):\n",
    "        print(f\"Advarsel: Kolonnen '{time_column}' er ikke en datetime-kolonne\")\n",
    "        return df\n",
    "\n",
    "    df_with_time = df.copy()\n",
    "    df_with_time['year'] = df_with_time[time_column].dt.year\n",
    "    df_with_time['month'] = df_with_time[time_column].dt.month\n",
    "    df_with_time['day'] = df_with_time[time_column].dt.day\n",
    "    df_with_time['hour'] = df_with_time[time_column].dt.hour\n",
    "\n",
    "    return df_with_time\n",
    "\n",
    "def create_geodataframe(df):\n",
    "    \"\"\"\n",
    "    Oppretter en GeoDataFrame fra en DataFrame ved å finne koordinater eller geometrikolonner.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sjekk for lat/long kolonner\n",
    "    if 'longitude' in df.columns and 'latitude' in df.columns:\n",
    "        try:\n",
    "            return gpd.GeoDataFrame(\n",
    "                df,\n",
    "                geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "                crs=STD_CRS\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Kunne ikke opprette geometri fra lat/long: {e}\")\n",
    "\n",
    "    # Sjekk for andre geometrikolonner\n",
    "    geom_columns = [col for col in df.columns if any(\n",
    "        term in col.lower() for term in ['geom', 'coord', 'point', 'polygon', 'linestring', 'wkt']\n",
    "    )]\n",
    "\n",
    "    for col in geom_columns:\n",
    "        if df[col].dtype != 'object':\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            geom = df[col].apply(wkt.loads)\n",
    "            return gpd.GeoDataFrame(df, geometry=geom, crs=STD_CRS)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_partitioned_geoparquet(gdf, output_path, partition_columns):\n",
    "    \"\"\"\n",
    "    Lagrer en GeoDataFrame som partisjonert GeoParquet.\n",
    "    \"\"\"\n",
    "    # Konverterer geometri til WKB for å kunne partisjonere\n",
    "    df_med_wkb = gdf.copy()\n",
    "    df_med_wkb['geometry_wkb'] = df_med_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    df_for_partisjon = df_med_wkb.drop(columns=['geometry'])\n",
    "    # Utfør partisjonering\n",
    "    df_for_partisjon.to_parquet(output_path, partition_cols=partition_columns)\n",
    "    # Konverter hver partisjonert fil tilbake til GeoParquet\n",
    "    convert_partitioned_files_to_geoparquet(output_path)\n",
    "    return output_path\n",
    "\n",
    "def create_year_folder(year, output_path):\n",
    "    \"\"\"Oppretter en mappe for et spesifikt år.\"\"\"\n",
    "    year_folder = os.path.join(output_path, f\"year={year}\")\n",
    "    os.makedirs(year_folder, exist_ok=True)\n",
    "    return year_folder\n",
    "\n",
    "def prepare_wkb_dataframe(year_df):\n",
    "    \"\"\"Forbereder en dataframe med WKB-konvertert geometri for partisjonering.\"\"\"\n",
    "    # Konverter geometri til WKB for å kunne partisjonere\n",
    "    year_df_wkb = year_df.copy()\n",
    "    year_df_wkb['geometry_wkb'] = year_df_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    year_df_wkb = year_df_wkb.drop(columns=['geometry'])\n",
    "    return year_df_wkb\n",
    "\n",
    "def convert_file_to_geoparquet(src_file, dst_file):\n",
    "    \"\"\"Konverterer en enkelt fil fra WKB-format til GeoParquet.\"\"\"\n",
    "    try:\n",
    "        part_df = pd.read_parquet(src_file)\n",
    "        if 'geometry_wkb' not in part_df.columns:\n",
    "            return False\n",
    "\n",
    "        part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "        part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "        part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=STD_CRS)\n",
    "\n",
    "        # Sørg for at målmappen eksisterer\n",
    "        os.makedirs(os.path.dirname(dst_file), exist_ok=True)\n",
    "        part_gdf.to_parquet(dst_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Advarsel: Kunne ikke konvertere {src_file} til GeoParquet: {e}\")\n",
    "        return False\n",
    "\n",
    "def copy_and_convert_files(temp_year_folder, year_folder):\n",
    "    \"\"\"Kopierer og konverterer filer fra temp-mappen til målmappen.\"\"\"\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    # Opprett først alle mappene\n",
    "    for root, dirs, _ in os.walk(temp_year_folder):\n",
    "        for directory in dirs:\n",
    "            src_dir = os.path.join(root, directory)\n",
    "            rel_path = os.path.relpath(src_dir, temp_year_folder)\n",
    "            dst_dir = os.path.join(year_folder, rel_path)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # Kopier og konverter filene\n",
    "    for root, _, files in os.walk(temp_year_folder):\n",
    "        for file in files:\n",
    "            src_file = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(src_file, temp_year_folder)\n",
    "            dst_file = os.path.join(year_folder, rel_path)\n",
    "\n",
    "            if convert_file_to_geoparquet(src_file, dst_file):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "\n",
    "    return success_count, error_count\n",
    "\n",
    "def convert_partitioned_files_to_geoparquet(PROCESSED_DIR):\n",
    "    \"\"\"\n",
    "    Konverterer alle partisjonerte parquet-filer til GeoParquet format.\n",
    "    \"\"\"\n",
    "    error_count = 0\n",
    "\n",
    "    for root, _, files in os.walk(PROCESSED_DIR):\n",
    "        for file in files:\n",
    "            if not file.endswith('.parquet'):\n",
    "                continue\n",
    "\n",
    "            parquet_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Les dataframe\n",
    "                part_df = pd.read_parquet(parquet_path)\n",
    "\n",
    "                # Hopp over hvis den ikke har geometry_wkb\n",
    "                if 'geometry_wkb' not in part_df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Konverter WKB tilbake til geometri\n",
    "                part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "                part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "\n",
    "                # Lag GeoDataFrame\n",
    "                part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=STD_CRS)\n",
    "\n",
    "                # Skriv GeoParquet-filen\n",
    "                part_gdf.to_parquet(parquet_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Feil ved konvertering av {parquet_path}: {e}\")\n",
    "                error_count += 1\n",
    "\n",
    "    if error_count > 0:\n",
    "        print(f\"Advarsel: {error_count} filer kunne ikke konverteres til GeoParquet\")\n",
    "\n",
    "def convert_parquet_to_geoparquet(file_path, output_path, partition_columns=None):\n",
    "    \"\"\"\n",
    "    Konverterer parquet-fil til GeoParquet-format med partisjonering.\n",
    "    Args:\n",
    "    file_path: Sti til parquet-filen\n",
    "    output_path: Sti hvor GeoParquet-filen skal lagres\n",
    "    partition_columns: Liste av kolonnenavn som skal brukes for partisjonering\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Kunne ikke lese parquet-fil: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Håndter tidspartisjonering\n",
    "    time_partitioning = False\n",
    "    if partition_columns and TIME_COLUMN in partition_columns:\n",
    "        partition_columns.remove(TIME_COLUMN)\n",
    "        time_partitioning = True\n",
    "\n",
    "    # Legg til alle tidspartisjoneringskolonner, men vi vil bare partisjonere på time\n",
    "    if time_partitioning:\n",
    "        df = add_time_partitioning_columns(df)\n",
    "        # Sett opp partisjonering kun på 'hour'\n",
    "        partition_columns = ['hour'] + (partition_columns or [])\n",
    "\n",
    "    # Opprett GeoDataFrame\n",
    "    gdf = create_geodataframe(df)\n",
    "    if gdf is None:\n",
    "        return False\n",
    "\n",
    "    # Sjekk at alle partisjoneringskolonner finnes\n",
    "    if partition_columns and not all(col in gdf.columns for col in partition_columns):\n",
    "        print(f\"Advarsel: Ikke alle partisjoneringskolonner finnes i datasettet\")\n",
    "        missing = [col for col in partition_columns if col not in gdf.columns]\n",
    "        print(f\"Manglende kolonner: {missing}\")\n",
    "        return False\n",
    "\n",
    "    # For partisjonering, må vi sikre at output_path er en mappe\n",
    "    if partition_columns:\n",
    "        # Sjekk om output_path slutter med .parquet\n",
    "        if output_path.endswith('.parquet'):\n",
    "            # Lag en mappe i stedet for en fil\n",
    "            directory_path = output_path\n",
    "            # Sikre at mappen eksisterer\n",
    "            os.makedirs(os.path.dirname(directory_path), exist_ok=True)\n",
    "        else:\n",
    "            directory_path = output_path\n",
    "\n",
    "        # Utfør partisjonering\n",
    "        return save_partitioned_geoparquet(gdf, directory_path, partition_columns)\n",
    "    else:\n",
    "        # Uten partisjonering, lagre direkte som fil\n",
    "        gdf.to_parquet(output_path)\n",
    "        return output_path\n",
    "\n",
    "def convert_all_parquet_files(DATA_DIR, partition_columns=None):\n",
    "    \"\"\"\n",
    "    Konverterer alle parquet-filer i en mappe til GeoParquet.\n",
    "    \"\"\"\n",
    "    raw_folder = os.path.join(DATA_DIR, \"raw\")\n",
    "    processed_folder = os.path.join(DATA_DIR, \"processed\")\n",
    "\n",
    "    results = {\n",
    "        \"converted\": [],\n",
    "        \"failed\": []\n",
    "    }\n",
    "\n",
    "    # Finn alle parquet-filer\n",
    "    parquet_files = [f for f in os.listdir(raw_folder)\n",
    "                    if f.lower().endswith('.parquet') and os.path.isfile(os.path.join(raw_folder, f))]\n",
    "\n",
    "    if not parquet_files:\n",
    "        print(\"Ingen parquet-filer funnet i råmappen\")\n",
    "        return results\n",
    "\n",
    "    # Konverter hver fil\n",
    "    for filename in parquet_files:\n",
    "        file_path = os.path.join(raw_folder, filename)\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "\n",
    "        # For partisjonering, lag en mappe i stedet for en fil\n",
    "        if partition_columns:\n",
    "            output_dir = os.path.join(processed_folder, base_filename)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_path = output_dir\n",
    "        else:\n",
    "            # For ingen partisjonering, bruk fil-path\n",
    "            output_path = os.path.join(processed_folder, f\"{base_filename}.parquet\")\n",
    "\n",
    "        # Konverter filen\n",
    "        resultat = convert_parquet_to_geoparquet(\n",
    "            file_path,\n",
    "            output_path,\n",
    "            partition_columns.copy() if partition_columns else None,\n",
    "        )\n",
    "\n",
    "        if resultat:\n",
    "            results[\"converted\"].append(file_path)\n",
    "        else:\n",
    "            results[\"failed\"].append(file_path)\n",
    "            print(f\"Kunne ikke konvertere: {file_path}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def start_conversion_with_metrics(DATA_DIR, partition_columns=None):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Starter konvertering og partisjonering av filer ...\\n\")\n",
    "    print(f\"Valgte kolonner: {partition_columns}\")\n",
    "    print(\"Vent litt...\")\n",
    "\n",
    "    #Utfør konverteringen\n",
    "    results = convert_all_parquet_files(DATA_DIR, partition_columns)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    print(\"\\nKonvertering og partisjonering utført:\")\n",
    "    print(f\"- Total behandlingstid: {total_time:.2f} sekunder\")\n",
    "    print(f\"- Konverterte filer: {len(results['converted'])}\")\n",
    "\n",
    "    # Mål filstørrelse av partisjonerte filer\n",
    "    total_partitioned_size_mb = 0\n",
    "    processed_folder = os.path.join(DATA_DIR, \"processed\")\n",
    "    for root, _, files in os.walk(processed_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.parquet'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                total_partitioned_size_mb += os.path.getsize(file_path) / (1024 * 1024)\n",
    "\n",
    "    return {\n",
    "        \"conversion_time\": total_time,\n",
    "        \"partitioned_filesize_mb\": total_partitioned_size_mb\n",
    "    }\n",
    "\n",
    "def get_total_raw_files_size(DATA_DIR):\n",
    "    raw_folder = os.path.join(DATA_DIR, \"raw\")\n",
    "    total_raw_size_mb = 0\n",
    "    for file in os.listdir(raw_folder):\n",
    "        file_path = os.path.join(raw_folder, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            total_raw_size_mb += os.path.getsize(file_path) / (1024 * 1024)\n",
    "    return total_raw_size_mb\n",
    "\n",
    "def get_memory_usage_mb():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 * 1024)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T20:54:29.832237Z",
     "start_time": "2025-04-26T20:54:29.829157Z"
    }
   },
   "cell_type": "code",
   "source": "create_folders(DATA_DIR);",
   "id": "191d6365d61decaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappestruktur opprettet.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "1f7d4c195e34d24a",
   "metadata": {},
   "source": [
    "# 3. Kjør konvertering med og uten partisjonering"
   ]
  },
  {
   "cell_type": "code",
   "id": "df2cef3e0499d6ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T20:54:44.609199Z",
     "start_time": "2025-04-26T20:54:41.585247Z"
    }
   },
   "source": [
    "# Mål original filstørrelse\n",
    "original_filesize_mb = get_total_raw_files_size(DATA_DIR)\n",
    "\n",
    "# Uten partisjonering\n",
    "memory_before_no_partition = get_memory_usage_mb()\n",
    "results_no_partition = start_conversion_with_metrics(DATA_DIR, partition_columns=None)\n",
    "memory_after_no_partition = get_memory_usage_mb()\n",
    "\n",
    "# Med partisjonering\n",
    "memory_before_partition = get_memory_usage_mb()\n",
    "results_partition = start_conversion_with_metrics(DATA_DIR, partition_columns=STD_PARTITION_COLUMNS)\n",
    "memory_after_partition = get_memory_usage_mb()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starter konvertering og partisjonering av filer ...\n",
      "\n",
      "Valgte kolonner: None\n",
      "Vent litt...\n",
      "\n",
      "Konvertering og partisjonering utført:\n",
      "- Total behandlingstid: 0.38 sekunder\n",
      "- Konverterte filer: 3\n",
      "Starter konvertering og partisjonering av filer ...\n",
      "\n",
      "Valgte kolonner: ['date_time_utc', 'ship_type']\n",
      "Vent litt...\n",
      "\n",
      "Konvertering og partisjonering utført:\n",
      "- Total behandlingstid: 2.64 sekunder\n",
      "- Konverterte filer: 3\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "38748c1fde12f6ca",
   "metadata": {},
   "source": [
    "# 4. Hvis resulater"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb080a46bf9e8707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T20:54:54.930025Z",
     "start_time": "2025-04-26T20:54:54.925470Z"
    }
   },
   "source": [
    "data = {\n",
    "    \"Metode\": [\"Uten Partisjonering\", \"Med Partisjonering\"],\n",
    "    \"Konverteringstid (sekunder)\": [results_no_partition[\"conversion_time\"], results_partition[\"conversion_time\"]],\n",
    "    \"Filstørrelse etter konvertering (MB)\": [original_filesize_mb, results_partition[\"partitioned_filesize_mb\"]],\n",
    "    \"Minnebruk før konvertering (MB)\": [memory_before_no_partition, memory_before_partition],\n",
    "    \"Minnebruk etter konvertering (MB)\": [memory_after_no_partition, memory_after_partition],\n",
    "    \"Minnebruk økning (MB)\": [memory_after_no_partition - memory_before_no_partition, memory_after_partition - memory_before_partition]\n",
    "\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(data)\n",
    "print(result_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Metode  Konverteringstid (sekunder)  \\\n",
      "0  Uten Partisjonering                     0.381436   \n",
      "1   Med Partisjonering                     2.635363   \n",
      "\n",
      "   Filstørrelse etter konvertering (MB)  Minnebruk før konvertering (MB)  \\\n",
      "0                              5.785349                        464.28125   \n",
      "1                             14.667778                        492.50000   \n",
      "\n",
      "   Minnebruk etter konvertering (MB)  Minnebruk økning (MB)  \n",
      "0                          492.50000               28.21875  \n",
      "1                          599.59375              107.09375  \n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
