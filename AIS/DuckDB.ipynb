{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importere",
   "id": "15f1690b90d253ff"
  },
  {
   "cell_type": "code",
   "id": "af45b7d1bbd47e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:16:55.284760Z",
     "start_time": "2025-05-11T16:16:54.793876Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkb\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Konstant variabler",
   "id": "1fcb8220dc3bb8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:16:59.985309Z",
     "start_time": "2025-05-11T16:16:59.982605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = Path().resolve()\n",
    "PROCESSED_DIR = ROOT_DIR /\"data\"/\"processed\""
   ],
   "id": "b7815f6f19ab591e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Opprett mappestruktur",
   "id": "bad81a48e55635da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:17:19.078692Z",
     "start_time": "2025-05-11T16:17:19.062843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def opprett_mappestruktur(data_mappe=\"./data\"):\n",
    "    \"\"\"\n",
    "    Oppretter nødvendig mappestruktur for konvertering.\n",
    "\n",
    "    Args:\n",
    "        data_mappe: Sti til hovedmappen for data\n",
    "\n",
    "    Returns:\n",
    "        dict: Stier til opprettede mapper\n",
    "    \"\"\"\n",
    "    # Definer mappestruktur\n",
    "    rå_mappe = os.path.join(data_mappe, \"raw\")\n",
    "    prosessert_mappe = os.path.join(data_mappe, \"processed\")\n",
    "    source_mappe = os.path.join(data_mappe, \"source\")\n",
    "    incoming_dir_mappe = os.path.join(data_mappe, \"incoming\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(data_mappe, exist_ok=True)\n",
    "    os.makedirs(rå_mappe, exist_ok=True)\n",
    "    os.makedirs(prosessert_mappe, exist_ok=True)\n",
    "    os.makedirs(source_mappe, exist_ok=True)\n",
    "    os.makedirs(incoming_dir_mappe, exist_ok=True)\n",
    "\n",
    "    print(f\"Mappestruktur opprettet.\")\n",
    "\n",
    "    # Returner stier for senere bruk\n",
    "    return {\n",
    "        \"data_mappe\": os.path.abspath(data_mappe),\n",
    "        \"rå_mappe\": os.path.abspath(rå_mappe),\n",
    "        \"prosessert_mappe\": os.path.abspath(prosessert_mappe),\n",
    "        \"source_mappe\": os.path.abspath(source_mappe),\n",
    "        \"incoming_mappe\": os.path.abspath(incoming_dir_mappe)\n",
    "    }\n",
    "\n",
    "def legg_til_tidspartisjoneringskolonner(df, tid_kolonne='date_time_utc'):\n",
    "    \"\"\"\n",
    "    Legger til kolonner for tidspartisjonering (kun time for partisjonering, men beholder dato-kolonner).\n",
    "    \"\"\"\n",
    "    if tid_kolonne not in df.columns:\n",
    "        print(f\"Advarsel: Tidsstempelkolonne '{tid_kolonne}' finnes ikke\")\n",
    "        return df\n",
    "\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[tid_kolonne]):\n",
    "        print(f\"Advarsel: Kolonnen '{tid_kolonne}' er ikke en datetime-kolonne\")\n",
    "        return df\n",
    "\n",
    "    df_med_tid = df.copy()\n",
    "    df_med_tid['year'] = df_med_tid[tid_kolonne].dt.year\n",
    "    df_med_tid['month'] = df_med_tid[tid_kolonne].dt.month\n",
    "    df_med_tid['day'] = df_med_tid[tid_kolonne].dt.day\n",
    "    df_med_tid['hour'] = df_med_tid[tid_kolonne].dt.hour\n",
    "\n",
    "    return df_med_tid\n",
    "\n",
    "def opprett_geodataframe(df):\n",
    "    \"\"\"\n",
    "    Oppretter en GeoDataFrame fra en DataFrame ved å finne koordinater eller geometrikolonner.\n",
    "    \"\"\"\n",
    "    from shapely import wkt\n",
    "    # Sjekk for lat/long kolonner\n",
    "    if 'longitude' in df.columns and 'latitude' in df.columns:\n",
    "        try:\n",
    "            return gpd.GeoDataFrame(\n",
    "                df,\n",
    "                geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "                crs=\"EPSG:4326\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Kunne ikke opprette geometri fra lat/long: {e}\")\n",
    "\n",
    "    # Sjekk for andre geometrikolonner\n",
    "    geom_kolonner = [col for col in df.columns if any(\n",
    "        term in col.lower() for term in ['geom', 'coord', 'point', 'polygon', 'linestring', 'wkt']\n",
    "    )]\n",
    "\n",
    "    for col in geom_kolonner:\n",
    "        if df[col].dtype != 'object':\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            geom = df[col].apply(wkt.loads)\n",
    "            return gpd.GeoDataFrame(df, geometry=geom, crs=\"EPSG:4326\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "\n",
    "def lagre_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner):\n",
    "    \"\"\"\n",
    "    Lagrer en GeoDataFrame som partisjonert GeoParquet.\n",
    "    \"\"\"\n",
    "    from shapely import wkb # NB!! Ikke fjern!\n",
    "\n",
    "    # Konverterer geometri til WKB for å kunne partisjonere\n",
    "    df_med_wkb = gdf.copy()\n",
    "    df_med_wkb['geometry_wkb'] = df_med_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    df_for_partisjon = df_med_wkb.drop(columns=['geometry'])\n",
    "\n",
    "    # Utfør partisjonering\n",
    "    df_for_partisjon.to_parquet(målfilsti, partition_cols=partisjon_kolonner)\n",
    "\n",
    "    # Konverter hver partisjonert fil tilbake til GeoParquet\n",
    "    konverter_partisjonerte_filer_til_geoparquet(målfilsti)\n",
    "    return målfilsti\n",
    "\n",
    "def opprett_år_mappe(år, målfilsti):\n",
    "    \"\"\"Oppretter en mappe for et spesifikt år.\"\"\"\n",
    "    år_mappe = os.path.join(målfilsti, f\"year={år}\")\n",
    "    os.makedirs(år_mappe, exist_ok=True)\n",
    "    return år_mappe\n",
    "\n",
    "def forbered_wkb_dataframe(år_df):\n",
    "    \"\"\"Forbereder en dataframe med WKB-konvertert geometri for partisjonering.\"\"\"\n",
    "    # Konverter geometri til WKB for å kunne partisjonere\n",
    "    år_df_wkb = år_df.copy()\n",
    "    år_df_wkb['geometry_wkb'] = år_df_wkb['geometry'].apply(lambda geom: wkb.dumps(geom))\n",
    "    år_df_wkb = år_df_wkb.drop(columns=['geometry'])\n",
    "    return år_df_wkb\n",
    "\n",
    "def konverter_fil_til_geoparquet(src_file, dst_file):\n",
    "    \"\"\"Konverterer en enkelt fil fra WKB-format til GeoParquet.\"\"\"\n",
    "    try:\n",
    "        part_df = pd.read_parquet(src_file)\n",
    "        if 'geometry_wkb' not in part_df.columns:\n",
    "            return False\n",
    "\n",
    "        part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "        part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "        part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "        # Sørg for at målmappen eksisterer\n",
    "        os.makedirs(os.path.dirname(dst_file), exist_ok=True)\n",
    "        part_gdf.to_parquet(dst_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Advarsel: Kunne ikke konvertere {src_file} til GeoParquet: {e}\")\n",
    "        return False\n",
    "\n",
    "def kopier_og_konverter_filer(temp_år_mappe, år_mappe):\n",
    "    \"\"\"Kopierer og konverterer filer fra temp-mappen til målmappen.\"\"\"\n",
    "    suksess_count = 0\n",
    "    feil_count = 0\n",
    "\n",
    "    # Opprett først alle mappene\n",
    "    for root, dirs, _ in os.walk(temp_år_mappe):\n",
    "        for directory in dirs:\n",
    "            src_dir = os.path.join(root, directory)\n",
    "            rel_path = os.path.relpath(src_dir, temp_år_mappe)\n",
    "            dst_dir = os.path.join(år_mappe, rel_path)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # Kopier og konverter filene\n",
    "    for root, _, files in os.walk(temp_år_mappe):\n",
    "        for file in files:\n",
    "            src_file = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(src_file, temp_år_mappe)\n",
    "            dst_file = os.path.join(år_mappe, rel_path)\n",
    "\n",
    "            if konverter_fil_til_geoparquet(src_file, dst_file):\n",
    "                suksess_count += 1\n",
    "            else:\n",
    "                feil_count += 1\n",
    "\n",
    "    return suksess_count, feil_count\n",
    "\n",
    "def konverter_partisjonerte_filer_til_geoparquet(rotmappe):\n",
    "    \"\"\"\n",
    "    Konverterer alle partisjonerte parquet-filer til GeoParquet format.\n",
    "    \"\"\"\n",
    "    from shapely import wkb # NB!! Ikke fjern!\n",
    "    feil_count = 0\n",
    "\n",
    "    for root, _, files in os.walk(rotmappe):\n",
    "        for file in files:\n",
    "            if not file.endswith('.parquet'):\n",
    "                continue\n",
    "\n",
    "            parquet_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Les dataframe\n",
    "                part_df = pd.read_parquet(parquet_path)\n",
    "\n",
    "                # Hopp over hvis den ikke har geometry_wkb\n",
    "                if 'geometry_wkb' not in part_df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Konverter WKB tilbake til geometri\n",
    "                part_df['geometry'] = part_df['geometry_wkb'].apply(lambda x: wkb.loads(x))\n",
    "                part_df = part_df.drop(columns=['geometry_wkb'])\n",
    "\n",
    "                # Lag GeoDataFrame\n",
    "                part_gdf = gpd.GeoDataFrame(part_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "                # Skriv GeoParquet-filen\n",
    "                part_gdf.to_parquet(parquet_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Feil ved konvertering av {parquet_path}: {e}\")\n",
    "                feil_count += 1\n",
    "\n",
    "    if feil_count > 0:\n",
    "        print(f\"Advarsel: {feil_count} filer kunne ikke konverteres til GeoParquet\")\n",
    "\n",
    "def konverter_parquet_til_geoparquet(filsti, målfilsti, partisjon_kolonner=None):\n",
    "    \"\"\"\n",
    "    Konverterer parquet-fil til GeoParquet-format med partisjonering.\n",
    "    Args:\n",
    "        filsti: Sti til parquet-filen\n",
    "        målfilsti: Sti hvor GeoParquet-filen skal lagres\n",
    "        partisjon_kolonner: Liste av kolonnenavn som skal brukes for partisjonering\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(filsti)\n",
    "    except Exception as e:\n",
    "        print(f\"Kunne ikke lese parquet-fil: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Håndter tidspartisjonering\n",
    "    tidspartisjonering = False\n",
    "    if partisjon_kolonner and 'date_time_utc' in partisjon_kolonner:\n",
    "        partisjon_kolonner.remove('date_time_utc')\n",
    "        tidspartisjonering = True\n",
    "\n",
    "    # Legg til alle tidspartisjoneringskolonner, men vi vil bare partisjonere på time\n",
    "    if tidspartisjonering:\n",
    "        df = legg_til_tidspartisjoneringskolonner(df)\n",
    "        # Sett opp partisjonering kun på 'hour'\n",
    "        partisjon_kolonner = ['hour'] + (partisjon_kolonner or [])\n",
    "\n",
    "    # Opprett GeoDataFrame\n",
    "    gdf = opprett_geodataframe(df)\n",
    "    if gdf is None:\n",
    "        return False\n",
    "\n",
    "    # Sjekk at alle partisjoneringskolonner finnes\n",
    "    if partisjon_kolonner and not all(col in gdf.columns for col in partisjon_kolonner):\n",
    "        print(f\"Advarsel: Ikke alle partisjoneringskolonner finnes i datasettet\")\n",
    "        manglende = [col for col in partisjon_kolonner if col not in gdf.columns]\n",
    "        print(f\"Manglende kolonner: {manglende}\")\n",
    "        return False\n",
    "\n",
    "    # Lagre med partisjonering (bare time)\n",
    "    if partisjon_kolonner:\n",
    "        return lagre_partisjonert_geoparquet(gdf, målfilsti, partisjon_kolonner)\n",
    "    else:\n",
    "        gdf.to_parquet(målfilsti)\n",
    "        return målfilsti\n",
    "\n",
    "def konverter_alle_parquet_filer(data_mappe, partisjon_kolonner=None):\n",
    "    \"\"\"\n",
    "    Konverterer alle parquet-filer i en mappe til GeoParquet.\n",
    "    \"\"\"\n",
    "    rå_mappe = os.path.join(data_mappe, \"raw\")\n",
    "    prosessert_mappe = os.path.join(data_mappe, \"processed\")\n",
    "\n",
    "    # Opprett mapper\n",
    "    os.makedirs(rå_mappe, exist_ok=True)\n",
    "    os.makedirs(prosessert_mappe, exist_ok=True)\n",
    "\n",
    "    resultater = {\n",
    "        \"konvertert\": [],\n",
    "        \"feilet\": []\n",
    "    }\n",
    "\n",
    "    # Finn alle parquet-filer\n",
    "    parquet_filer = [f for f in os.listdir(rå_mappe)\n",
    "                     if f.lower().endswith('.parquet') and os.path.isfile(os.path.join(rå_mappe, f))]\n",
    "\n",
    "    if not parquet_filer:\n",
    "        print(\"Ingen parquet-filer funnet i råmappen\")\n",
    "        return resultater\n",
    "\n",
    "    # Konverter hver fil\n",
    "    for filnavn in parquet_filer:\n",
    "        filsti = os.path.join(rå_mappe, filnavn)\n",
    "        base_filnavn = os.path.splitext(filnavn)[0]\n",
    "        målfilsti = os.path.join(prosessert_mappe, f\"{base_filnavn}.parquet\")\n",
    "\n",
    "        # Konverter filen\n",
    "        resultat = konverter_parquet_til_geoparquet(\n",
    "            filsti,\n",
    "            målfilsti,\n",
    "            partisjon_kolonner.copy() if partisjon_kolonner else None,\n",
    "        )\n",
    "\n",
    "        if resultat:\n",
    "            resultater[\"konvertert\"].append(filsti)\n",
    "        else:\n",
    "            resultater[\"feilet\"].append(filsti)\n",
    "            print(f\"Kunne ikke konvertere: {filsti}\")\n",
    "\n",
    "    return resultater\n",
    "\n",
    "def vis_partisjoneringsstruktur(konvertert_sti):\n",
    "    \"\"\"\n",
    "    Viser partisjoneringsstrukturen for en konvertert fil.\n",
    "    \"\"\"\n",
    "\n",
    "    for root, dirs, files in os.walk(konvertert_sti, topdown=True, followlinks=False):\n",
    "        nivå = root.replace(konvertert_sti, \"\").count(os.sep)\n",
    "        innrykk = \"    \" * (nivå + 1)\n",
    "\n",
    "        # Vis mappenavnet\n",
    "        mappe_navn = os.path.basename(root)\n",
    "        if mappe_navn:  # Ikke vis for rot-mappen\n",
    "            print(f\"{innrykk}- {mappe_navn}\")\n",
    "\n",
    "        # Vis antall filer i dypeste mapper\n",
    "        if not dirs and files:\n",
    "            print(f\"{innrykk}  Inneholder {len(files)} filer\")\n",
    "\n",
    "def vis_datasett_info(filsti):\n",
    "    \"\"\"\n",
    "    Viser informasjon om et GeoParquet datasett.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gdf = gpd.read_parquet(filsti)\n",
    "        print(f\"  Datasett størrelse: {len(gdf)} rader, {len(gdf.columns)} kolonner\")\n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(f\"  Kunne ikke lese filen: {e}\")\n",
    "        return None\n",
    "\n",
    "def start_konvertering(data_mappe=\"./data\", partisjon_kolonner=None):\n",
    "    \"\"\"\n",
    "    Start konverteringsprosessen fra Parquet til GeoParquet.\n",
    "    Args:\n",
    "        data_mappe: Sti til datamappen\n",
    "        partisjon_kolonner: Liste av kolonner for partisjonering\n",
    "    \"\"\"\n",
    "    start_tid = time.time()\n",
    "    print(f\"Starter konvertering og partisjonering av parquet-filer i {data_mappe} ...\\n\")\n",
    "    print(f\"Partisjonering vil skje på 'hour' og følgende kolonner: {partisjon_kolonner or []}\")\n",
    "\n",
    "    # Opprett og sjekk mappene\n",
    "    mappestier = opprett_mappestruktur(data_mappe)\n",
    "    rå_mappe = mappestier[\"rå_mappe\"]\n",
    "\n",
    "    # Utfør konverteringen\n",
    "    resultater = konverter_alle_parquet_filer(data_mappe, partisjon_kolonner)\n",
    "\n",
    "    print(\"Konvertering og partisjonering utført:\")\n",
    "    print(f\"• Total behandlingstid: {time.time() - start_tid:.2f} sekunder\")\n",
    "    print(f\"• Konverterte filer: {len(resultater['konvertert'])}\")\n",
    "\n",
    "    return resultater"
   ],
   "id": "8f39633550349337",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Kjør mappestruktur funksjonen",
   "id": "8b08e9ed3d302a90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:01:58.869307Z",
     "start_time": "2025-05-11T18:01:58.864056Z"
    }
   },
   "cell_type": "code",
   "source": "mappestier = opprett_mappestruktur()",
   "id": "f8a03212d1536b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappestruktur opprettet.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Kun konvertering",
   "id": "40719917aa237b9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:02:50.884441Z",
     "start_time": "2025-05-11T18:02:34.401314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# resultater = start_konvertering(data_mappe=\"./data\")\n",
    "\n",
    "# Manuell konvertering og partisjonering\n",
    "resultater = start_konvertering(data_mappe=\"./data\", partisjon_kolonner=[\"date_time_utc\", \"ship_type\"])"
   ],
   "id": "56919d49f8aebd47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starter konvertering og partisjonering av parquet-filer i ./data ...\n",
      "\n",
      "Partisjonering vil skje på 'hour' og følgende kolonner: ['date_time_utc', 'ship_type']\n",
      "Mappestruktur opprettet.\n",
      "Konvertering og partisjonering utført:\n",
      "• Total behandlingstid: 16.48 sekunder\n",
      "• Konverterte filer: 4\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sett inn verdier og kjør funskjonen for filtrering!",
   "id": "6640c67fd4b0e27f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T19:44:56.615192Z",
     "start_time": "2025-05-11T19:44:56.572441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_filtered_ais_data_spatial(\n",
    "    base_path: str,\n",
    "    ship_type: int,\n",
    "    center_lat: float,\n",
    "    center_lon: float,\n",
    "    buffer_radius_m: float,\n",
    "    start_date: str,\n",
    "    start_time: str,\n",
    "    end_date: str,\n",
    "    end_time: str,\n",
    "    max_rows: int\n",
    ") -> tuple[pd.DataFrame,int]:\n",
    "    \"\"\"\n",
    "    Leser alle parquet-filer under base_path, bruker DuckDB til å filtrere på:\n",
    "      - ship_type\n",
    "      - tidsrom\n",
    "      - innenfor buffer\n",
    "      - Innenfor områdekode\n",
    "\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(base_path, \"**\", \"*.parquet*\")\n",
    "    files = glob.glob(pattern, recursive=True)\n",
    "    if not files:\n",
    "        raise IOError(f\"Ingen filer funnet for mønster {pattern!r}\")\n",
    "\n",
    "    # Bygg WHERE-klausul\n",
    "    where = []\n",
    "    if ship_type != 0:\n",
    "        where.append(f\"ship_type = {ship_type}\")\n",
    "\n",
    "    def make_ts(d, t, is_end=False):\n",
    "        if d in (\"\", \"0\"):\n",
    "            return None\n",
    "        if t in (\"\", \"0\"):\n",
    "            t = \"23:59:59\" if is_end else \"00:00:00\"\n",
    "        return f\"TIMESTAMP '{d} {t}'\"\n",
    "\n",
    "    ts_start = make_ts(start_date, start_time, is_end=False)\n",
    "    ts_end   = make_ts(end_date,   end_time,   is_end=True)\n",
    "\n",
    "    if ts_start and ts_end:\n",
    "        where.append(f\"date_time_utc BETWEEN {ts_start} AND {ts_end}\")\n",
    "    elif ts_start:\n",
    "        if end_date in (\"\", \"0\"):\n",
    "            if start_time in (\"\", \"0\"):\n",
    "                where.append(f\"CAST(date_time_utc AS DATE) = DATE '{start_date}'\")\n",
    "            else:\n",
    "                where.append(f\"date_time_utc >= {ts_start}\")\n",
    "                where.append(f\"date_time_utc <= TIMESTAMP '{start_date} 23:59:59'\")\n",
    "        else:\n",
    "            where.append(f\"date_time_utc >= {ts_start}\")\n",
    "    elif ts_end:\n",
    "        where.append(f\"date_time_utc <= {ts_end}\")\n",
    "\n",
    "    # Bufferfiltrering\n",
    "    radius_deg = buffer_radius_m / 111000.0\n",
    "    where.append(\n",
    "        f\"ST_Distance(geometry, ST_GeomFromText('POINT({center_lon} {center_lat})')) <= {radius_deg}\"\n",
    "    )\n",
    "\n",
    "    where_clause = \"\"\n",
    "    if where:\n",
    "        where_clause = \" WHERE \" + \" AND \".join(where)\n",
    "\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"INSTALL spatial;\")\n",
    "    con.execute(\"LOAD spatial;\")\n",
    "\n",
    "    # Tell totalt antall rader\n",
    "    count_sql = f\"SELECT COUNT(*) AS cnt FROM read_parquet('{pattern}'){where_clause}\"\n",
    "    total_count = con.execute(count_sql).fetchone()[0]\n",
    "\n",
    "    # Hent data med LIMIT\n",
    "    select_sql = (\n",
    "        f\"SELECT * FROM read_parquet('{pattern}')\" +\n",
    "        where_clause +\n",
    "        \" ORDER BY date_time_utc\"\n",
    "    )\n",
    "    if max_rows and max_rows > 0:\n",
    "        select_sql += f\" LIMIT {max_rows}\"\n",
    "\n",
    "    df = con.execute(select_sql).fetchdf()\n",
    "    con.close()\n",
    "    return df, total_count\n",
    "\n",
    "def render_ais_map(\n",
    "    df: pd.DataFrame,\n",
    "    center_lat: float,\n",
    "    center_lon: float,\n",
    "    buffer_radius_m: float\n",
    ") -> folium.Map:\n",
    "    \"\"\"\n",
    "    Tegner buffer og skips-posisjoner med clusters på et kart.\n",
    "    \"\"\"\n",
    "    m = folium.Map(location=[center_lat, center_lon],\n",
    "                   zoom_start=12,\n",
    "                   tiles=\"cartodb positron\")\n",
    "    folium.Circle(\n",
    "        location=[center_lat, center_lon],\n",
    "        radius=buffer_radius_m,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_opacity=0.1,\n",
    "        popup=\"Bufferområde\"\n",
    "    ).add_to(m)\n",
    "\n",
    "    cluster = MarkerCluster().add_to(m)\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.notnull(row.longitude) and pd.notnull(row.latitude):\n",
    "            folium.Marker(\n",
    "                location=[row.latitude, row.longitude],\n",
    "                popup=(\n",
    "                    f\"MMSI: {row.mmsi}<br>\"\n",
    "                    f\"Time: {row.date_time_utc}<br>\"\n",
    "                    f\"Lon/Lat: {row.longitude:.4f}, {row.latitude:.4f}\"\n",
    "                ),\n",
    "                icon=folium.Icon(color='red', icon='info-sign')\n",
    "            ).add_to(cluster)\n",
    "    return m\n",
    "\n",
    "# Filvalg\n",
    "base_path_label  = widgets.Label(\"Filbane:\")\n",
    "base_path_widget = widgets.Text(value= str(PROCESSED_DIR), layout=widgets.Layout(width='600px'))\n",
    "load_button      = widgets.Button(description=\"Last filsti\", button_style='info', layout=widgets.Layout(width='150px'))\n",
    "file_output      = widgets.Output()\n",
    "\n",
    "# Filterfelt\n",
    "ship_type_label   = widgets.Label(\"Ship Type (0 = alle):\")\n",
    "ship_type_widget  = widgets.IntText(value=0, layout=widgets.Layout(width='200px'))\n",
    "\n",
    "lat_label         = widgets.Label(\"Koordinat (Lat):\")\n",
    "center_lat_widget = widgets.FloatText(value=58.142359, layout=widgets.Layout(width='200px'))\n",
    "\n",
    "lon_label         = widgets.Label(\"Koordinat (Lon):\")\n",
    "center_lon_widget = widgets.FloatText(value=8.025218, layout=widgets.Layout(width='200px'))\n",
    "\n",
    "radius_label      = widgets.Label(\"Buffer i meter:\")\n",
    "radius_widget     = widgets.IntText(value=6000, layout=widgets.Layout(width='200px'))\n",
    "\n",
    "start_date_label  = widgets.Label(\"Start-dato (YYYY-MM-DD):\")\n",
    "start_date_widget = widgets.Text(value='2025-01-21', layout=widgets.Layout(width='200px'))\n",
    "start_time_label  = widgets.Label(\"Start-tid (HH:MM:SS eller 0 for å ignorere):\")\n",
    "start_time_widget = widgets.Text(value='0', layout=widgets.Layout(width='200px'))\n",
    "\n",
    "end_date_label    = widgets.Label(\"Slutt-dato (YYYY-MM-DD eller 0 for å ignorere):\")\n",
    "end_date_widget   = widgets.Text(value='0', layout=widgets.Layout(width='200px'))\n",
    "end_time_label    = widgets.Label(\"Slutt-tid (HH:MM:SS eller 0 for å ignorere):\")\n",
    "end_time_widget   = widgets.Text(value='0', layout=widgets.Layout(width='200px'))\n",
    "\n",
    "max_rows_label    = widgets.Label(\"Maks rader:\")\n",
    "max_rows_widget   = widgets.IntText(value=10, layout=widgets.Layout(width='200px'))\n",
    "\n",
    "run_button    = widgets.Button(description=\"Utfør filtrering\", button_style='info', layout=widgets.Layout(width='150px'))\n",
    "run_output    = widgets.Output()\n",
    "\n",
    "filter_widgets_box = widgets.VBox([\n",
    "    ship_type_label,   ship_type_widget,\n",
    "    lat_label,         center_lat_widget,\n",
    "    lon_label,         center_lon_widget,\n",
    "    radius_label,      radius_widget,\n",
    "    start_date_label,  start_date_widget,\n",
    "    start_time_label,  start_time_widget,\n",
    "    end_date_label,    end_date_widget,\n",
    "    end_time_label,    end_time_widget,\n",
    "    max_rows_label,    max_rows_widget,\n",
    "    run_button,        run_output\n",
    "])\n",
    "filter_widgets_box.layout.display = 'none'\n",
    "\n",
    "# Vis kun filvalg først\n",
    "display(widgets.VBox([\n",
    "    base_path_label, base_path_widget,\n",
    "    load_button, file_output,\n",
    "    filter_widgets_box\n",
    "]))\n",
    "\n",
    "# Handlere\n",
    "\n",
    "def on_load_clicked(b):\n",
    "    with file_output:\n",
    "        file_output.clear_output()\n",
    "        base = base_path_widget.value.strip()\n",
    "        pattern = os.path.join(base, \"**\", \"*.parquet*\")\n",
    "        files = glob.glob(pattern, recursive=True)\n",
    "        if not files:\n",
    "            print(f\"Feil: Ingen filer funnet under {base!r}\")\n",
    "            return\n",
    "        print(f\"Fant {len(files)} parquet-filer. Angi filtre under.\")\n",
    "        filter_widgets_box.layout.display = ''\n",
    "\n",
    "load_button.on_click(on_load_clicked)\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    with run_output:\n",
    "        run_output.clear_output()\n",
    "        try:\n",
    "            df, total_count = get_filtered_ais_data_spatial(\n",
    "                base_path=base_path_widget.value.strip(),\n",
    "                ship_type=ship_type_widget.value,\n",
    "                center_lat=center_lat_widget.value,\n",
    "                center_lon=center_lon_widget.value,\n",
    "                buffer_radius_m=radius_widget.value,\n",
    "                start_date=start_date_widget.value.strip(),\n",
    "                start_time=start_time_widget.value.strip(),\n",
    "                end_date=end_date_widget.value.strip(),\n",
    "                end_time=end_time_widget.value.strip(),\n",
    "                max_rows=max_rows_widget.value\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Feil ved henting av data:\", e)\n",
    "            return\n",
    "\n",
    "        shown = len(df)\n",
    "        print(f\"Hentet totalt {total_count} rader. Viser {shown} rader.\")\n",
    "        display(df)\n",
    "\n",
    "        m = render_ais_map(\n",
    "            df,\n",
    "            center_lat_widget.value,\n",
    "            center_lon_widget.value,\n",
    "            radius_widget.value\n",
    "        )\n",
    "        display(m)\n",
    "\n",
    "        # Eksporterer filen\n",
    "        out_file = \"data/filtered_result_ais_duckDB.parquet\"\n",
    "        df.to_parquet(out_file, index=False)\n",
    "\n",
    "        # Leser filstørrelsen\n",
    "        size_bytes = os.path.getsize(out_file)\n",
    "\n",
    "        # Konventerer til MK/MB for pen utskrift\n",
    "        size_kb = size_bytes / 1024\n",
    "        if size_kb < 1024:\n",
    "            size_str = f\"{size_kb:.2f} KB\"\n",
    "        else:\n",
    "            size_str = f\"{size_kb/1024:.2f} MB\"\n",
    "        print(f\"Resultatet er eksportert til '{out_file}', størrelse: {size_str}\")\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n"
   ],
   "id": "4ee33293739c7cc1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Filbane:'), Text(value='/Users/ineantonsen/Desktop/Bachelor-V25/repo/kaidata_geola…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb736692930047329fb6a176d062eadf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
